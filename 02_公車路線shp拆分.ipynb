{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443279da",
   "metadata": {},
   "source": [
    "# Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23e79f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os \n",
    "from shapely import wkt # for WKT 轉幾何物件\n",
    "from shapely.geometry import LineString, Point, MultiLineString\n",
    "from shapely.ops import substring, linemerge\n",
    "\n",
    "# ===== 自己新增所使用的套件 =====\n",
    "from TDXdataframe import read_bus_stop_of_route_xml, read_bus_shape_of_route_xml, read_businfo_xml, read_displayofroute_xml\n",
    "from basicprocess import create_folder, findfiles, read_combined_dataframe, updatelog\n",
    "\n",
    "# 00 Setup\n",
    "def dataframe_to_point(df, lon_col, lat_col, crs=\"EPSG:4326\", target_crs=\"EPSG:3826\"):\n",
    "    '''\n",
    "    Parameters:\n",
    "    df (dataframe) : 含經緯度座標欄位的dataframe\n",
    "    lon_col (str) : 緯度欄位\n",
    "    Lat_col (str) : 經度欄位\n",
    "    crs (str) : 目前經緯度座標的座標系統，常用的為4326(WGS84)、3826(TWD97)\n",
    "    target_crs：目標轉換的座標系統\n",
    "    '''\n",
    "\n",
    "    # from shapely.geometry import Point\n",
    "    # import pandas as pd\n",
    "    # import geopandas as gpd\n",
    "    # Create Point geometries from the longitude and latitude columns\n",
    "    geometry = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]\n",
    "    # Create a GeoDataFrame with the original CRS\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=crs)\n",
    "    # Convert the GeoDataFrame to the target CRS\n",
    "    gdf = gdf.to_crs(epsg=target_crs.split(\":\")[1])\n",
    "    return gdf\n",
    "\n",
    "# 01 讀取TDX資料\n",
    "# 讀取 TDXdataframe\n",
    "\n",
    "# 02 檢查路線\n",
    "def compare_column_values(df_a, df_b, column, name_a='df_a', name_b='df_b'):\n",
    "    # 轉 set 做比較\n",
    "    set_a = set(df_a[column])\n",
    "    set_b = set(df_b[column])\n",
    "\n",
    "    only_in_a = set_a - set_b\n",
    "    only_in_b = set_b - set_a\n",
    "    in_both = set_a & set_b\n",
    "\n",
    "    # 組成輸出用文字\n",
    "    text = []\n",
    "    text.append(f\"只在 {name_a} 出現的 {column}：{len(only_in_a)}\")\n",
    "    text.append(f\"只在 {name_b} 出現的 {column}：{len(only_in_b)}\")\n",
    "    text.append(f\"兩邊都有的 {column}：{len(in_both)}\")\n",
    "\n",
    "    output_text = \"\\n\".join(text)\n",
    "\n",
    "    return output_text, only_in_a, only_in_b, in_both\n",
    "\n",
    "# 03 拆分路線\n",
    "\n",
    "def snap_points_to_line(\n",
    "    stops_gdf, routes_gdf,\n",
    "    route_id_col, route_direction_col,\n",
    "    seq_id_col, seq_direction_col,\n",
    "    seq_lat_col, seq_lng_col,\n",
    "    route_geom_col=\"geometry\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    不處理 CRS、不檢查任何欄位、不做 eps 修正。\n",
    "    只負責把點投影到路線上並回寫 __m__。\n",
    "    \"\"\"\n",
    "\n",
    "    snapped_points = []\n",
    "    measures = []\n",
    "\n",
    "    for _, stop in stops_gdf.iterrows():\n",
    "\n",
    "        # 找對應路線\n",
    "        matching = routes_gdf[\n",
    "            (routes_gdf[route_id_col] == stop[seq_id_col]) &\n",
    "            (routes_gdf[route_direction_col] == stop[seq_direction_col])\n",
    "        ]\n",
    "\n",
    "        if matching.empty:\n",
    "            snapped_points.append(stop.geometry)\n",
    "            measures.append(None)\n",
    "            continue\n",
    "\n",
    "        geom = matching.iloc[0][route_geom_col]\n",
    "\n",
    "        # MultiLineString 盡量合併成單線\n",
    "        try:\n",
    "            line = linemerge(geom)\n",
    "        except Exception:\n",
    "            line = geom\n",
    "\n",
    "        # 投影與插值\n",
    "        m = line.project(stop.geometry)\n",
    "        snapped = line.interpolate(m)\n",
    "\n",
    "        snapped_points.append(snapped)\n",
    "        measures.append(float(m))\n",
    "\n",
    "    out = stops_gdf.copy()\n",
    "    out[\"geometry\"] = snapped_points\n",
    "    out[seq_lat_col] = out.geometry.y\n",
    "    out[seq_lng_col] = out.geometry.x\n",
    "    out[\"__m__\"] = measures\n",
    "\n",
    "    return out\n",
    "\n",
    "def split_routes(\n",
    "    busroute_select, \n",
    "    seq_select,\n",
    "    route_id_col='RouteName',\n",
    "    route_direction_col='Direction',\n",
    "    seq_id_col='RouteName',\n",
    "    seq_direction_col='Direction',\n",
    "    seq_seq_col='Seq',\n",
    "    route_geom_col='geometry',\n",
    "    eps=1e-6 ):\n",
    "    \"\"\"\n",
    "    依站序把路線切成多段，只輸出 LineString 段落。\n",
    "    要求 seq_select 已經由 snap_points_to_line 產生 __m__ 欄位；若沒有，我們會用 geometry 計算。\n",
    "    \"\"\"\n",
    "    output = []\n",
    "\n",
    "    # CRSs 對齊\n",
    "    if hasattr(busroute_select, \"crs\") and hasattr(seq_select, \"crs\"):\n",
    "        if busroute_select.crs != seq_select.crs:\n",
    "            seq_select = seq_select.to_crs(busroute_select.crs)\n",
    "\n",
    "    for _, route in busroute_select.iterrows():\n",
    "        rid = route[route_id_col]\n",
    "        direc = route[route_direction_col]\n",
    "        geom = route[route_geom_col]\n",
    "\n",
    "        # 先把路線合併成單條（盡量）\n",
    "        try:\n",
    "            line = linemerge(geom)\n",
    "        except Exception:\n",
    "            line = geom\n",
    "\n",
    "        # 取對應站點（依站序排序）\n",
    "        stops = seq_select[\n",
    "            (seq_select[seq_id_col] == rid) &\n",
    "            (seq_select[seq_direction_col] == direc)\n",
    "        ].sort_values(seq_seq_col).copy()\n",
    "\n",
    "        if stops.empty:\n",
    "            continue\n",
    "\n",
    "        # 若沒有 __m__ 就現算\n",
    "        if \"__m__\" not in stops.columns or stops[\"__m__\"].isna().any():\n",
    "            stops[\"__m__\"] = stops.geometry.apply(lambda p: line.project(p))\n",
    "\n",
    "        # 夾界在 [0, line.length]\n",
    "        L = line.length\n",
    "        stops[\"__m__\"] = stops[\"__m__\"].clip(lower=0.0, upper=L)\n",
    "\n",
    "        # 去除「同一 m 值」的重複點（避免零長度段）\n",
    "        # 若同一 m 有多筆，保留站序最小的那一筆\n",
    "        stops = stops.sort_values([ \"__m__\", seq_seq_col ])\n",
    "        stops = stops.drop_duplicates(subset=\"__m__\", keep=\"first\")\n",
    "\n",
    "        # 回到站序順序（你要依站序切段）\n",
    "        stops = stops.sort_values(seq_seq_col)\n",
    "\n",
    "        m_vals = stops[\"__m__\"].to_numpy()\n",
    "        seq_vals = stops[seq_seq_col].to_numpy()\n",
    "\n",
    "        for i in range(len(m_vals) - 1):\n",
    "            m0 = float(m_vals[i])\n",
    "            m1 = float(m_vals[i+1])\n",
    "\n",
    "            # 修正順序：substring 需要 start <= end\n",
    "            start_m = min(m0, m1)\n",
    "            end_m   = max(m0, m1)\n",
    "\n",
    "            # 過濾太短或同點（避免回傳 Point）\n",
    "            if end_m - start_m <= eps:\n",
    "                continue\n",
    "\n",
    "            # 切段\n",
    "            seg = substring(line, start_m, end_m, normalized=False)\n",
    "\n",
    "            # 只保留 LineString（或非零長度的 MultiLineString）\n",
    "            if isinstance(seg, LineString):\n",
    "                if seg.length > eps:\n",
    "                    output.append({\n",
    "                        'ID': rid,\n",
    "                        'Direction': direc,\n",
    "                        'StartSeq': seq_vals[i],\n",
    "                        'EndSeq': seq_vals[i+1],\n",
    "                        'geometry': seg\n",
    "                    })\n",
    "            elif isinstance(seg, MultiLineString):\n",
    "                # 可能因為 line 還是多段，挑長度>0的子段各自輸出\n",
    "                for part in seg.geoms:\n",
    "                    if part.length > eps:\n",
    "                        output.append({\n",
    "                            'ID': rid,\n",
    "                            'Direction': direc,\n",
    "                            'StartSeq': seq_vals[i],\n",
    "                            'EndSeq': seq_vals[i+1],\n",
    "                            'geometry': part\n",
    "                        })\n",
    "            else:\n",
    "                # Point / 空幾何都丟掉\n",
    "                continue\n",
    "\n",
    "    return gpd.GeoDataFrame(output, geometry=\"geometry\", crs=getattr(busroute_select, \"crs\", None))\n",
    "\n",
    "def inspect_route_geometries(gdf):\n",
    "    \"\"\"\n",
    "    檢查 GeoDataFrame 的 geometry 型別，並回傳文字報告（string）。\n",
    "    不做 print，只組成 text 回傳。\n",
    "    \"\"\"\n",
    "\n",
    "    lines = []  # 用來存文字行\n",
    "\n",
    "    lines.append(\"幾何型別分佈：\")\n",
    "    geom_counts = gdf.geom_type.value_counts(dropna=False)\n",
    "    lines.append(str(geom_counts))\n",
    "\n",
    "    # 找出非 LineString / MultiLineString，或空幾何、NaN\n",
    "    mask_bad = (\n",
    "        ~gdf.geom_type.isin([\"LineString\", \"MultiLineString\"])\n",
    "        | gdf.geometry.isna()\n",
    "        | gdf.is_empty\n",
    "    )\n",
    "    bad = gdf[mask_bad]\n",
    "\n",
    "    lines.append(f\"\\n疑似有問題的筆數：{len(bad)}\")\n",
    "\n",
    "    bad_geom_types = bad.geom_type.value_counts(dropna=False).rename(\"bad_geom_types\")\n",
    "    lines.append(str(bad_geom_types))\n",
    "\n",
    "    # 前幾筆索引\n",
    "    bad_indices = list(bad.index[:10])\n",
    "    lines.append(f\"\\n前 10 筆問題索引：{bad_indices}\")\n",
    "\n",
    "    # 將所有行組成字串\n",
    "    text_report = \"\\n\".join(lines)\n",
    "    return text_report\n",
    "\n",
    "\n",
    "# ===== 步驟 =====\n",
    "# 01-01 讀取站序xml\n",
    "def read_seq(busstopseq_folder = os.path.join(os.getcwd(), '..', \"00_TDX資料下載\", \"01公車站序資料\"), reset_seq = True):\n",
    "    # 讀取所有站序 xml，轉存為 csv\n",
    "    xml_files = findfiles(busstopseq_folder, filetype='.xml', recursive=False)\n",
    "    for xmlfile in xml_files:\n",
    "        outputfile_csvpath = xmlfile.replace('.xml', '.csv')\n",
    "        if os.path.exists(outputfile_csvpath) == False:\n",
    "            df = read_bus_stop_of_route_xml(xmlfile)\n",
    "            df.to_csv(outputfile_csvpath, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # 整併所有的csv\n",
    "    df_seq = read_combined_dataframe(findfiles(busstopseq_folder, filetype='.csv', recursive=False))\n",
    "    df_seq = df_seq.drop_duplicates(subset=['RouteUID', 'SubRouteID', 'Direction', 'StopSequence'])\n",
    "\n",
    "    if reset_seq == True:\n",
    "        df_seq = (\n",
    "            df_seq\n",
    "            .sort_values(['RouteUID', 'SubRouteUID', 'Direction', 'StopSequence'])\n",
    "            .assign(\n",
    "                Seq_real=lambda d: (\n",
    "                    d.groupby(['RouteUID', 'SubRouteUID', 'Direction'])\n",
    "                    .cumcount() + 1\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        df_seq['Ori_seq'] = df_seq['StopSequence']\n",
    "        df_seq['StopSequence'] = df_seq['Seq_real']\n",
    "\n",
    "\n",
    "    return df_seq\n",
    "\n",
    "# 01-02 讀取路線xml資料\n",
    "def read_busroute(busroute_folder = os.path.join(os.getcwd(), '..', \"00_TDX資料下載\", \"02公車路線資料\")):\n",
    "    xml_files = findfiles(busroute_folder, filetype='.xml', recursive=False)\n",
    "    for xmlfile in xml_files:\n",
    "        outputfile_csvpath = xmlfile.replace('.xml', '.csv')\n",
    "        if os.path.exists(outputfile_csvpath) == False:\n",
    "            df = read_bus_shape_of_route_xml(xmlfile)\n",
    "            df.to_csv(outputfile_csvpath, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # 整併所有的csv\n",
    "    df_route = read_combined_dataframe(findfiles(busroute_folder, filetype='.csv', recursive=False))\n",
    "    df_route = df_route.drop_duplicates(subset=['RouteUID', 'SubRouteID', 'Direction'])\n",
    "\n",
    "    return df_route\n",
    "\n",
    "# 02 檢查路線\n",
    "def check_routes_and_save(df_route, df_seq, output_path=\"route_check_output.txt\"):\n",
    "    # 呼叫 compare_column_values\n",
    "    text_routeUID, only_in_route_routeUID, only_in_seq_routeUID, in_both_routeUID = compare_column_values(\n",
    "        df_route, df_seq, 'RouteUID', name_a='df_route', name_b='df_seq'\n",
    "    )\n",
    "    text_subrouteUID, only_in_route_subrouteUID, only_in_seq_subrouteUID, in_both_subrouteUID = compare_column_values(\n",
    "        df_route, df_seq, 'SubRouteUID', name_a='df_route', name_b='df_seq'\n",
    "    )\n",
    "\n",
    "    # 組合所有輸出文字\n",
    "    output_text = (\n",
    "        text_routeUID + \"\\n\"\n",
    "        + \"-----------\\n\"\n",
    "        + text_subrouteUID\n",
    "    )\n",
    "\n",
    "    # 寫入 txt 檔\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output_text)\n",
    "\n",
    "    print(f\"已輸出檢查結果到：{output_path}\")\n",
    "    return in_both_subrouteUID\n",
    "def read_routeinfo(inputfolder = os.path.join('..', '00_TDX資料下載', '03公車路線營運資料')):\n",
    "    busrouteinfofiles = findfiles(inputfolder, 'xml')\n",
    "    routeinfo = []\n",
    "    for file in busrouteinfofiles:\n",
    "        routeinfo.append(read_businfo_xml(file))\n",
    "    df_routeinfo = pd.concat(routeinfo)\n",
    "    df_routeinfo = df_routeinfo.rename(columns = {'RouteNameZh':'RouteName_Zh', 'SubRouteNameZh':'SubRouteName_Zh'})\n",
    "    return df_routeinfo\n",
    "def compare_uid_sets(A, B, Acol, Bcol, dropna=True):\n",
    "    \"\"\"\n",
    "    比較兩個 DataFrame 指定欄位的集合差異\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A, B : pandas.DataFrame\n",
    "    Acol, Bcol : str\n",
    "        要比較的欄位名稱\n",
    "    dropna : bool, default True\n",
    "        是否忽略 NaN（建議 True）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {\n",
    "            'common': set,\n",
    "            'only_in_A': set,\n",
    "            'only_in_B': set,\n",
    "            'A_common_df': DataFrame,\n",
    "            'A_only_df': DataFrame,\n",
    "            'B_common_df': DataFrame,\n",
    "            'B_only_df': DataFrame\n",
    "        }\n",
    "    \"\"\"\n",
    "    if dropna:\n",
    "        set_A = set(A[Acol].dropna())\n",
    "        set_B = set(B[Bcol].dropna())\n",
    "    else:\n",
    "        set_A = set(A[Acol])\n",
    "        set_B = set(B[Bcol])\n",
    "\n",
    "    common = set_A & set_B\n",
    "    only_A = set_A - set_B\n",
    "    only_B = set_B - set_A\n",
    "\n",
    "    return {\n",
    "        'common': common,\n",
    "        'only_in_A': only_A,\n",
    "        'only_in_B': only_B,\n",
    "        'A_common_df': A[A[Acol].isin(common)],\n",
    "        'A_only_df': A[A[Acol].isin(only_A)],\n",
    "        'B_common_df': B[B[Bcol].isin(common)],\n",
    "        'B_only_df': B[B[Bcol].isin(only_B)],\n",
    "    }\n",
    "def fillin_dfroute_subrouteuid(df_seq, df_route, accurate=True):\n",
    "\n",
    "    if accurate == True:\n",
    "        updatelog(file = logfile, text = '[info]:僅更新同時有RouteUID、Direction、SubRouteUID 的唯一組合')\n",
    "    else:\n",
    "        updatelog(file = logfile, text = '[warn]:同時有RouteUID、Direction的組合， 因此可能會有多個SubRouteUID，但實際上無法確認是否為相同的路線')\n",
    "\n",
    "    df_seq = df_seq.copy()\n",
    "    df_route = df_route.copy()\n",
    "    updatelog(file = logfile, text = f'[info]:原始的線形資料共有{len(df_route):,} 筆')\n",
    "\n",
    "    routecolumns = df_route.columns.to_list()\n",
    "\n",
    "    reindex_columns = ['RouteUID',  'RouteName_Zh', 'SubRouteUID', 'SubRouteName_Zh', 'Direction']\n",
    "    df_seq = df_seq.reindex(columns = reindex_columns).drop_duplicates()\n",
    "\n",
    "    df_seq['R_S_UID'] = (\n",
    "        df_seq['RouteUID'].fillna('')\n",
    "        + '-'\n",
    "        + df_seq['SubRouteUID'].fillna('')\n",
    "    )\n",
    "\n",
    "    df_route['R_S_UID'] = (\n",
    "        df_route['RouteUID'].fillna('')\n",
    "        + '-'\n",
    "        + df_route['SubRouteUID'].fillna('')\n",
    "    )\n",
    "\n",
    "    updatelog(file = logfile, text = '[info]:進行比對RouteUID & SubRouteUID組合')\n",
    "    returnlist = compare_uid_sets(A = df_route, B = df_seq, Acol = 'R_S_UID', Bcol = 'R_S_UID', dropna=True)\n",
    "    commonlist = returnlist['common']\n",
    "    onlyinroute = returnlist['A_only_df']\n",
    "    onlyinseq = returnlist['B_only_df']\n",
    "    route_common_df = returnlist['A_common_df']\n",
    "    seq_common_df = returnlist['B_common_df']\n",
    "\n",
    "    # 一、找出現在站序僅有唯一組合的SubRouteUID\n",
    "    updatelog(file = logfile, text = '[info]:找出現在站序僅有唯一組合的SubRouteUID')\n",
    "    temp = onlyinseq.groupby(['RouteUID', 'Direction']).agg(Count=('SubRouteUID', 'count'), \n",
    "                                                            RouteName_Zh = ('RouteName_Zh', 'first'), \n",
    "                                                            SubRouteName_Zh = ('SubRouteName_Zh', 'first'),\n",
    "                                                            R_S_UID=('R_S_UID', lambda x: ','.join(x.astype(str).unique())),\n",
    "                                                            SubRouteUID=('SubRouteUID', lambda x: ','.join(x.astype(str).unique())) # 堆疊出所有的SubRouteUID\n",
    "                                                            ).reset_index().reindex(columns = ['RouteUID',  'RouteName_Zh','SubRouteName_Zh', 'Direction', 'R_S_UID', 'SubRouteUID', 'Count'])\n",
    "\n",
    "    routeuidlist_1 = list(temp[temp['Count'] == 1]['RouteUID'].unique()) # 代表在df_seq之中RouteUID、Direction、SubRouteUID只會有一組組合 但沒有被配對到的 \n",
    "    seq_forpairing = temp[(temp['RouteUID'].isin(routeuidlist_1)) & (~temp['R_S_UID'].isin(commonlist))] #需要同時間排除是在共同清單裡的 也需要是在這個「唯一組合」的\n",
    "    updatelog(file = logfile, text = f'[warn]:找出唯一組合的RouteUID共有 {len(routeuidlist_1):,} 的RouteUID')\n",
    "\n",
    "    # 二、找到原本df_route 與 第一步的唯一配對組合 routeuidlist_1 相同的RouteUID 給他們所謂的SubRouteUID\n",
    "    ok_pairingroute = pd.merge(onlyinroute[onlyinroute['RouteUID'].isin(routeuidlist_1)].drop(columns = ['SubRouteName_Zh', 'SubRouteUID', 'R_S_UID']),\n",
    "                            seq_forpairing.drop(columns = 'RouteName_Zh'), \n",
    "                            on = ['RouteUID', 'Direction'], \n",
    "                            how = 'left')\n",
    "    ok_pairingroute = ok_pairingroute.reindex(columns = routecolumns)\n",
    "    updatelog(file=logfile,\n",
    "              text=f\"[warn]:配對到1:1的SubRouteUID {len(ok_pairingroute[~ok_pairingroute['SubRouteUID'].isna()]):,} 筆\")\n",
    "\n",
    "\n",
    "    # 加入返回處理\n",
    "    onlyinroute = onlyinroute[~onlyinroute['RouteUID'].isin(routeuidlist_1)] #沒有routeUID 後續要處理的資料\n",
    "    route_common_df = pd.concat([route_common_df, ok_pairingroute])\n",
    "\n",
    "    route_common_df = (\n",
    "        route_common_df\n",
    "        .assign(SubRouteUID=route_common_df['SubRouteUID'].str.split(','))\n",
    "        .explode('SubRouteUID')\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "\n",
    "    updatelog(\n",
    "        file=logfile,\n",
    "        text=f\"[warn]:剩餘沒有配對成功的有 {len(onlyinroute):,} 筆\"\n",
    "    )\n",
    "    onlyinroute_severalsubrouteuid = pd.merge(onlyinroute[~(onlyinroute['RouteUID'].isin(routeuidlist_1))].drop(columns = ['SubRouteName_Zh', 'SubRouteUID', 'R_S_UID']),\n",
    "                                            onlyinseq[(~onlyinseq['RouteUID'].isin(routeuidlist_1))].drop(columns = ['RouteName_Zh']).drop_duplicates(),\n",
    "                                            on = ['RouteUID', 'Direction'], \n",
    "                                            how = 'left')\n",
    "                                            \n",
    "    updatelog(\n",
    "        file=logfile,\n",
    "        text=f\"[warn]:剩餘沒有配對成功的線形資料配對後 增為 {len(onlyinroute_severalsubrouteuid[onlyinroute_severalsubrouteuid['SubRouteUID'].notna()]):,} 筆\"\n",
    "    )\n",
    "    if accurate == True:\n",
    "        output = route_common_df\n",
    "    else : \n",
    "        output = pd.concat([route_common_df, onlyinroute_severalsubrouteuid])\n",
    "\n",
    "    return output.reindex(columns = routecolumns).sort_index(), ok_pairingroute, seq_forpairing\n",
    "\n",
    "# 03 拆分路線\n",
    "\n",
    "# 03-01 將站序和路線轉為 GeoDataFrame\n",
    "def get_gdfroute_gdfseq(df_route, df_seq):\n",
    "    '''03-01 將站序和路線轉為 GeoDataFrame'''\n",
    "    df_route = df_route.copy()\n",
    "    df_seq = df_seq.copy()\n",
    "    \n",
    "    # df_route[\"Geometry\"] = df_route[\"Geometry\"].apply(wkt.loads) # 將 Geometry 欄位的 WKT 轉為 shapely geometry \n",
    "    # gdf_route = gpd.GeoDataFrame(df_route, geometry=\"Geometry\", crs=\"EPSG:4326\") # 建立 GeoDataFrame \n",
    "    # gdf_route.rename(columns={'Geometry':'geometry'}, inplace=True)\n",
    "\n",
    "    df_route[\"geometry\"] = df_route[\"Geometry\"].apply(wkt.loads)\n",
    "    df_route = df_route.drop(columns = 'Geometry')\n",
    "    gdf_route = gpd.GeoDataFrame(\n",
    "        df_route,\n",
    "        geometry=\"geometry\",\n",
    "        crs=\"EPSG:4326\"\n",
    "    )    \n",
    "\n",
    "    gdf_seq = dataframe_to_point(df_seq, lon_col='PositionLon', lat_col='PositionLat', crs=\"EPSG:4326\", target_crs=\"EPSG:4326\")\n",
    "\n",
    "    return gdf_route, gdf_seq\n",
    "\n",
    "# 03-02 拆分路線\n",
    "def get_bySubRouteUID(gdf_route, gdf_seq, in_both_subrouteUID):\n",
    "\n",
    "    # 先處理SubRouteUID 一致的路線\n",
    "    gdf_route_selectbySubRouteUID = gdf_route[gdf_route['SubRouteUID'].isin(in_both_subrouteUID)].reset_index(drop=True)\n",
    "    gdf_seq_selectbySubRouteUID = gdf_seq[gdf_seq['SubRouteUID'].isin(in_both_subrouteUID)].reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # 將公車站序點位投影到路線上\n",
    "    gdf_snapstop_select = snap_points_to_line(gdf_seq_selectbySubRouteUID, gdf_route_selectbySubRouteUID,\n",
    "                                            route_id_col='SubRouteUID',\n",
    "                                            route_direction_col='Direction',\n",
    "                                            seq_id_col='SubRouteUID',\n",
    "                                            seq_direction_col='Direction',\n",
    "                                            seq_lat_col='PositionLat',\n",
    "                                            seq_lng_col='PositionLon')\n",
    "    # 依站序拆分路線\n",
    "    gdf_routesegment_select = split_routes(gdf_route_selectbySubRouteUID, gdf_snapstop_select,\n",
    "                                        route_id_col='SubRouteUID',\n",
    "                                        route_direction_col='Direction',\n",
    "                                        seq_id_col='SubRouteUID',\n",
    "                                        seq_direction_col='Direction',\n",
    "                                        seq_seq_col='StopSequence')\n",
    "\n",
    "    gdf_routesegment_select.rename(columns = {'ID':'SubRouteUID'}, inplace=True)\n",
    "    gdf_routesegment_select = pd.merge(gdf_routesegment_select,\n",
    "                                        gdf_seq_selectbySubRouteUID[['RouteUID', 'RouteName_Zh' ,'SubRouteUID', 'SubRouteName_Zh']].drop_duplicates(subset=['RouteUID', 'SubRouteUID']),\n",
    "                                        on='SubRouteUID', how='left')\n",
    "    gdf_routesegment_select = pd.merge(gdf_routesegment_select,\n",
    "                                        gdf_seq_selectbySubRouteUID[['RouteUID', 'SubRouteUID', 'Direction', 'StopSequence', 'StopUID', 'StopName_Zh']].rename(columns={'StopUID':'OStopUID', 'StopName_Zh':'OStopName', 'StopSequence':'StartSeq'}).drop_duplicates(subset=['RouteUID', 'SubRouteUID', 'Direction', 'StartSeq']),\n",
    "                                        on=['RouteUID', 'SubRouteUID', 'Direction', 'StartSeq'], how='left')\n",
    "    \n",
    "    gdf_routesegment_select = pd.merge(gdf_routesegment_select,\n",
    "                                        gdf_seq_selectbySubRouteUID[['RouteUID', 'SubRouteUID', 'Direction', 'StopSequence', 'StopUID', 'StopName_Zh']].rename(columns={'StopUID':'DStopUID', 'StopName_Zh':'DStopName', 'StopSequence':'EndSeq'}).drop_duplicates(subset=['RouteUID', 'SubRouteUID', 'Direction', 'EndSeq']),\n",
    "                                        on=['RouteUID', 'SubRouteUID', 'Direction', 'EndSeq'], how='left')\n",
    "    \n",
    "    gdf_routesegment_select = gdf_routesegment_select.rename(columns = {'RouteName_Zh':'RouteName', 'SubRouteName_Zh':'SubRouteName'})\n",
    "\n",
    "    return gdf_routesegment_select\n",
    "\n",
    "def get_byRouteUID(gdf_route, gdf_seq, in_both_subrouteUID):\n",
    "\n",
    "    gdf_route_others = gdf_route[gdf_route['SubRouteUID'].isin(in_both_subrouteUID)==False]\n",
    "    gdf_seq_others = gdf_seq[gdf_seq['SubRouteUID'].isin(in_both_subrouteUID) == False]\n",
    "\n",
    "    gdf_snapstop_others = snap_points_to_line(gdf_seq_others, gdf_route_others,\n",
    "                                            route_id_col='RouteUID',\n",
    "                                            route_direction_col='Direction',\n",
    "                                            seq_id_col='RouteUID',\n",
    "                                            seq_direction_col='Direction',\n",
    "                                            seq_lat_col='PositionLat',\n",
    "                                            seq_lng_col='PositionLon')\n",
    "\n",
    "    gdf_routesegment_others = split_routes(gdf_route_others, gdf_snapstop_others,\n",
    "                                        route_id_col='RouteUID',\n",
    "                                        route_direction_col='Direction',\n",
    "                                        seq_id_col='RouteUID',\n",
    "                                        seq_direction_col='Direction',\n",
    "                                        seq_seq_col='StopSequence')\n",
    "\n",
    "    gdf_routesegment_others.rename(columns = {'ID':'RouteUID'}, inplace=True)\n",
    "\n",
    "\n",
    "    gdf_routesegment_others = gdf_routesegment_others.merge(gdf_route_others[['RouteUID', 'RouteName_Zh']].drop_duplicates(), on='RouteUID', how='left')\n",
    "    gdf_routesegment_others = pd.merge(gdf_routesegment_others , \n",
    "                                    gdf_seq_others[['RouteUID', 'Direction', 'StopSequence', 'StopUID', 'StopName_Zh']].drop_duplicates().rename(columns = {'StopUID':'OstopUID', 'StopName_Zh':'OStopName',  'StopSequence':'StartSeq'}), \n",
    "                                    on = ['RouteUID', 'Direction', 'StartSeq'], how = 'left')\n",
    "    gdf_routesegment_others = pd.merge(gdf_routesegment_others , \n",
    "                                    gdf_seq_others[['RouteUID', 'Direction', 'StopSequence', 'StopUID', 'StopName_Zh']].drop_duplicates().rename(columns = {'StopUID':'DstopUID', 'StopName_Zh':'DStopName',  'StopSequence':'EndSeq'}), \n",
    "                                    on = ['RouteUID', 'Direction', 'EndSeq'], how = 'left')\n",
    "    \n",
    "    gdf_routesegment_others = gdf_routesegment_others.rename(columns = {'RouteName_Zh':'RouteName'})\n",
    "\n",
    "    return gdf_routesegment_others\n",
    "\n",
    "def get_splitroute(gdf_route, gdf_seq, in_both_subrouteUID, \n",
    "                   routesegment_folder = create_folder(os.path.join(os.getcwd(), '..', \"03_處理後資料\", \"01_公車路線依站序拆分\")), \n",
    "                   enable_separate_output = True):\n",
    "    '''黏貼路網成步驟'''\n",
    "\n",
    "    # 處理SubRouteUID 一致的路線\n",
    "    gdf_routesegment_select = get_bySubRouteUID(gdf_route, gdf_seq, in_both_subrouteUID)\n",
    "    if enable_separate_output:\n",
    "        gdf_routesegment_select.to_file(os.path.join(routesegment_folder, 'BySubRouteUID.shp'), index=False)\n",
    "\n",
    "    # 處理只有RouteUID 一致的路線\n",
    "    gdf_routesegment_others = get_byRouteUID(gdf_route, gdf_seq, in_both_subrouteUID)\n",
    "    if enable_separate_output:\n",
    "        gdf_routesegment_others.to_file(os.path.join(routesegment_folder, 'ByRouteUID.shp'), index=False)\n",
    "\n",
    "    # 最後合併\n",
    "    gdf_routesegment = pd.concat([gdf_routesegment_select, gdf_routesegment_others], ignore_index=True)\n",
    "    gdf_routesegment = gdf_routesegment.reindex(columns = ['RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', 'Direction', \n",
    "                                                           'StartSeq', 'OStopName', 'OStopUID', \n",
    "                                                           'EndSeq', 'DStopName', 'DStopUID', \n",
    "                                                           'geometry'])\n",
    "    \n",
    "\n",
    "    print(inspect_route_geometries(gdf_routesegment))\n",
    "\n",
    "    # 輸出\n",
    "    routesegment_filepath = os.path.join(routesegment_folder, '市區公車拆分.shp')\n",
    "    gdf_routesegment.to_file(routesegment_filepath, \n",
    "                             index=False)\n",
    "    \n",
    "    return gdf_routesegment\n",
    "\n",
    "# 全域函數\n",
    "logfile = os.path.abspath(os.path.join(os.getcwd(), '..', '02_公車路線shp拆分.txt'))\n",
    "def main():\n",
    "    df_seq = read_seq(busstopseq_folder = os.path.join(os.getcwd(), '..', \"00_TDX資料下載\", \"01公車站序資料\"))\n",
    "    df_route = read_busroute(busroute_folder = os.path.join(os.getcwd(), '..', \"00_TDX資料下載\", \"02公車路線資料\"))\n",
    "    df_route = fillin_dfroute_subrouteuid(df_seq=df_seq, df_route=df_route, accurate=False).sort_index()\n",
    "\n",
    "    in_both_subrouteUID = check_routes_and_save(df_route = df_route, \n",
    "                                                df_seq = df_seq, \n",
    "                                                output_path= os.path.abspath(os.path.join(os.getcwd(), '..', '02_初步分析', '票證及路線數據檢查.txt')))\n",
    "    \n",
    "    gdf_route, gdf_seq = get_gdfroute_gdfseq(df_route, df_seq)\n",
    "\n",
    "    gdf_routesegment = get_splitroute(gdf_route = gdf_route, \n",
    "                                  gdf_seq = gdf_seq, \n",
    "                                  in_both_subrouteUID = in_both_subrouteUID)\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795d0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54afcabb",
   "metadata": {},
   "source": [
    "# 開始嘗試讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a747dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已輸出檢查結果到：d:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\02_初步分析\\票證及路線數據檢查.txt\n"
     ]
    }
   ],
   "source": [
    "updatelog(file = logfile, text = '[info]:執行02_公車路線shp拆分.ipynb')\n",
    "\n",
    "updatelog(file = logfile, text = '[info]:讀取站序資料(df_seq)')\n",
    "df_seq = read_seq(busstopseq_folder = os.path.join(os.getcwd(), '..', \"00_TDX資料下載\", \"01公車站序資料\"))\n",
    "\n",
    "updatelog(file = logfile, text = '[info]:讀取公車路線線形資料(df_route)')\n",
    "df_route = read_busroute(busroute_folder = os.path.join(os.getcwd(), '..', \"00_TDX資料下載\", \"02公車路線資料\"))\n",
    "# df_routeinfo = read_routeinfo()\n",
    "# df_seq = filter_by_keywords(df=df_seq, filtercolumn='SubRouteName_Zh', filterlist=['寵物'])\n",
    "\n",
    "updatelog(file = logfile, text = '[info]:更新目前沒有SubRouteUID的資料')\n",
    "df_route,ok_pairingroute, seq_forpairing = fillin_dfroute_subrouteuid(df_seq=df_seq, df_route=df_route, accurate=True)\n",
    "\n",
    "updatelog(file = logfile, text = '[info]:計算出取交集的subrouteUID，以利進行路線拆解')\n",
    "in_both_subrouteUID = check_routes_and_save(df_route = df_route, \n",
    "                                            df_seq = df_seq, \n",
    "                                            output_path= os.path.abspath(os.path.join(os.getcwd(), '..', '02_初步分析', '票證及路線數據檢查.txt')))\n",
    "\n",
    "updatelog(file = logfile, text = '[info]:將dataframe(df_route、df_seq) 轉為 圖形資料')\n",
    "gdf_route, gdf_seq = get_gdfroute_gdfseq(df_route, df_seq)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9b13b",
   "metadata": {},
   "source": [
    "# 嘗試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dfa77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_route, gdf_seq = get_gdfroute_gdfseq(df_route, df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9920cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_points_to_line(stops_gdf, \n",
    "                        routes_gdf, \n",
    "                        route_id_col, \n",
    "                        route_direction_col, \n",
    "                        seq_id_col, \n",
    "                        seq_direction_col, \n",
    "                        seq_lat_col, \n",
    "                        seq_lng_col):\n",
    "    \"\"\"\n",
    "    將公車站點 (stops_gdf) 投影到公車路線 (routes_gdf) 上，並動態帶入欄位名稱。\n",
    "    Parameters:\n",
    "        stops_gdf (GeoDataFrame): 包含公車站點的 GeoDataFrame。\n",
    "        routes_gdf (GeoDataFrame): 包含公車路線的 GeoDataFrame。\n",
    "        route_id_col (str): 路線名稱欄位名稱。\n",
    "        route_direction_col (str): 路線方向欄位名稱。\n",
    "        seq_routename_col (str): 站點路線名稱欄位名稱。\n",
    "        seq_direction_col (str): 站點方向欄位名稱。\n",
    "        seq_lat_col (str): 站點緯度欄位名稱。\n",
    "        seq_lng_col (str): 站點經度欄位名稱。\n",
    "    Returns:\n",
    "        GeoDataFrame: 更新後的公車站點 GeoDataFrame，其中 geometry 已投影到路線。\n",
    "    \"\"\"\n",
    "    snapped_points = []\n",
    "\n",
    "    for _, stop in stops_gdf.iterrows():\n",
    "        # 找到與站點路線名稱和方向相符的路線\n",
    "        matching_route = routes_gdf[(routes_gdf[route_id_col] == stop[seq_id_col]) & \n",
    "                                    (routes_gdf[route_direction_col] == stop[seq_direction_col])]\n",
    "\n",
    "        if not matching_route.empty:\n",
    "            # 取出該路線的 geometry\n",
    "            line = matching_route.iloc[0].geometry\n",
    "            # 計算站點投影到該路線的最近點\n",
    "            snapped_point = line.interpolate(line.project(stop.geometry))\n",
    "            snapped_points.append(snapped_point)\n",
    "        else:\n",
    "            # 如果沒有匹配的路線，保持原點\n",
    "            snapped_points.append(stop.geometry)\n",
    "\n",
    "    # 更新站點的 geometry\n",
    "    stops_gdf = stops_gdf.copy()\n",
    "    stops_gdf['geometry'] = snapped_points\n",
    "    stops_gdf[seq_lat_col] = stops_gdf.geometry.y\n",
    "    stops_gdf[seq_lng_col] = stops_gdf.geometry.x\n",
    "    return stops_gdf\n",
    "\n",
    "def split_routes(busroute_select, \n",
    "                 seq_select,\n",
    "                 route_id_col='RouteName',\n",
    "                 route_direction_col='Direction',\n",
    "                 seq_id_col='RouteName',\n",
    "                 seq_direction_col='Direction',\n",
    "                 seq_seq_col='Seq',\n",
    "                 seq_lat_col='Lat',\n",
    "                 seq_lng_col='Lon'):\n",
    "    \"\"\"\n",
    "    將公車路線 (busroute_select) 依據提供的站序 (seq_select) 上，分為數段的shp。\n",
    "    Parameters:\n",
    "        busroute_select (GeoDataFrame): 包含公車路線名稱的 GeoDataFrame。\n",
    "        seq_select (DataFrame): 包含公車路線站序的 DataFrame。\n",
    "        seq_routename_col (str): 路線名稱欄位名稱。\n",
    "        seq_direction_col (str): 路線方向欄位名稱。\n",
    "        seq_seq_col (str): 站點方向欄位名稱。\n",
    "        seq_lat_col (str): 站點緯度欄位名稱。\n",
    "        seq_lng_col (str): 站點經度欄位名稱。\n",
    "    Returns:\n",
    "        GeoDataFrame: 更新後的公車站點 GeoDataFrame，其中 geometry 已投影到路線。\n",
    "    \"\"\"\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for _, route in busroute_select.iterrows():\n",
    "        route_id = route[route_id_col]\n",
    "        direction = route[route_direction_col]\n",
    "        geometry = route['geometry']\n",
    "\n",
    "        # 過濾對應路線與方向的站點\n",
    "        stops = seq_select[(seq_select[seq_id_col] == route_id) & \n",
    "                           (seq_select[seq_direction_col] == direction)].sort_values(seq_seq_col)\n",
    "\n",
    "        # 確保站點順序對應於路線\n",
    "        stop_coords = [(row[seq_lng_col], row[seq_lat_col]) for _, row in stops.iterrows()]\n",
    "\n",
    "        for i in range(len(stop_coords) - 1):\n",
    "            start_point = Point(stop_coords[i])\n",
    "            end_point = Point(stop_coords[i + 1])\n",
    "\n",
    "            # 找到站點在路線中的比例位置\n",
    "            start_distance = geometry.project(start_point)\n",
    "            end_distance = geometry.project(end_point)\n",
    "\n",
    "            # 提取路線幾何分段\n",
    "            segment = substring(geometry, start_distance, end_distance)\n",
    "\n",
    "            output.append({\n",
    "                'RouteName': route_id,\n",
    "                'Direction': direction,\n",
    "                'StartSeq': stops.iloc[i][seq_seq_col],\n",
    "                'EndSeq': stops.iloc[i + 1][seq_seq_col],\n",
    "                'geometry': segment\n",
    "            })\n",
    "\n",
    "    return gpd.GeoDataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kjchang\\AppData\\Local\\Temp\\ipykernel_36776\\1339621017.py:82: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf_snappoints.to_file(os.path.join(outputfolder, 'SnappedSequence.shp'))\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'RouteName_Zh' to 'RouteName_'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'RouteName_En' to 'RouteNam_1'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'SubRouteUID' to 'SubRouteUI'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'SubRouteName_Zh' to 'SubRouteNa'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'SubRouteName_En' to 'SubRoute_1'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'OperatorName_Zh' to 'OperatorNa'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StopName_Zh' to 'StopName_Z'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StopName_En' to 'StopName_E'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StopBoarding' to 'StopBoardi'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StopSequence' to 'StopSequen'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'PositionLon' to 'PositionLo'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'PositionLat' to 'PositionLa'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StationGroupID' to 'StationGro'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'LocationCityCode' to 'LocationCi'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Temp\\ipykernel_36776\\1339621017.py:87: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  original_gdfseq.to_file(os.path.join(outputfolder, 'original_gdfseq.shp'))\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'RouteName_Zh' to 'RouteName_'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'RouteName_En' to 'RouteNam_1'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'SubRouteUID' to 'SubRouteUI'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'SubRouteName_Zh' to 'SubRouteNa'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'SubRouteName_En' to 'SubRoute_1'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'OperatorName_Zh' to 'OperatorNa'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StopName_Zh' to 'StopName_Z'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StopName_En' to 'StopName_E'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StopBoarding' to 'StopBoardi'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StopSequence' to 'StopSequen'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'PositionLon' to 'PositionLo'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'PositionLat' to 'PositionLa'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'StationGroupID' to 'StationGro'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'LocationCityCode' to 'LocationCi'\n",
      "  ogr_write(\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Temp\\ipykernel_36776\\1339621017.py:92: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  original_gdfroute.to_file(os.path.join(outputfolder, 'original_gdfroute.shp'))\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'SubRouteUID' to 'SubRouteUI'\n",
      "  ogr_write(\n"
     ]
    },
    {
     "ename": "FeatureError",
     "evalue": "Could not add feature to layer at index 23987: Attempt to write non-linestring (POINT) geometry to ARC type shapefile.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFeatureError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     96\u001b[39m gdf_segment_routes = pd.concat(gdf_segment_routes)\n\u001b[32m     97\u001b[39m gdf_segment_routes_line = gdf_segment_routes[gdf_segment_routes.geometry.type.isin([\u001b[33m'\u001b[39m\u001b[33mLineString\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMultiLineString\u001b[39m\u001b[33m'\u001b[39m])]\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mgdf_segment_routes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgdf_segment_routes.shp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m updatelog(file = logfile, text = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[info]: gdf_segment_routes 輸出成功\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\geopandas\\geodataframe.py:1637\u001b[39m, in \u001b[36mGeoDataFrame.to_file\u001b[39m\u001b[34m(self, filename, driver, schema, index, **kwargs)\u001b[39m\n\u001b[32m   1543\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[32m   1544\u001b[39m \n\u001b[32m   1545\u001b[39m \u001b[33;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1633\u001b[39m \n\u001b[32m   1634\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[32m-> \u001b[39m\u001b[32m1637\u001b[39m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\geopandas\\io\\file.py:731\u001b[39m, in \u001b[36m_to_file\u001b[39m\u001b[34m(df, filename, driver, schema, index, mode, crs, engine, metadata, **kwargs)\u001b[39m\n\u001b[32m    728\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m should be one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, got \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyogrio\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m     \u001b[43m_to_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mfiona\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    733\u001b[39m     _to_file_fiona(df, filename, driver, schema, crs, mode, metadata, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\geopandas\\io\\file.py:793\u001b[39m, in \u001b[36m_to_file_pyogrio\u001b[39m\u001b[34m(df, filename, driver, schema, crs, mode, metadata, **kwargs)\u001b[39m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df.columns.is_unique:\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mGeoDataFrame cannot contain duplicated column names.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m \u001b[43mpyogrio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\geopandas.py:710\u001b[39m, in \u001b[36mwrite_dataframe\u001b[39m\u001b[34m(df, path, layer, driver, encoding, geometry_type, promote_to_multi, nan_as_null, append, use_arrow, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, **kwargs)\u001b[39m\n\u001b[32m    707\u001b[39m         field_data.append(values)\n\u001b[32m    708\u001b[39m         field_mask.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:723\u001b[39m, in \u001b[36mwrite\u001b[39m\u001b[34m(path, geometry, field_data, fields, field_mask, layer, driver, geometry_type, crs, encoding, promote_to_multi, nan_as_null, append, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, gdal_tz_offsets, **kwargs)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;66;03m# preprocess kwargs and split in dataset and layer creation options\u001b[39;00m\n\u001b[32m    719\u001b[39m dataset_kwargs, layer_kwargs = _preprocess_options_kwargs(\n\u001b[32m    720\u001b[39m     driver, dataset_options, layer_options, kwargs\n\u001b[32m    721\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m \u001b[43mogr_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:2677\u001b[39m, in \u001b[36mpyogrio._io.ogr_write\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFeatureError\u001b[39m: Could not add feature to layer at index 23987: Attempt to write non-linestring (POINT) geometry to ARC type shapefile."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 先處理SubRouteUID 一致的路線\n",
    "outputfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\Trial1218\"\n",
    "\n",
    "route_id_col='SubRouteUID'\n",
    "route_direction_col='Direction'\n",
    "seq_id_col='SubRouteUID'\n",
    "seq_direction_col='Direction'\n",
    "seq_seq_col = 'StopSequence'\n",
    "seq_lat_col='PositionLat'\n",
    "seq_lng_col='PositionLon'\n",
    "\n",
    "busroute = gdf_route[gdf_route['SubRouteUID'].isin(in_both_subrouteUID)].reset_index(drop=True)\n",
    "seq = gdf_seq[gdf_seq['SubRouteUID'].isin(in_both_subrouteUID)].reset_index(drop=True)\n",
    "\n",
    "gdf_segment_routes = []\n",
    "gdf_snappoints = []\n",
    "\n",
    "original_gdfseq = []\n",
    "original_gdfroute = []\n",
    "\n",
    "for route in list(in_both_subrouteUID):\n",
    "    for direction in [0,1]:\n",
    "            # 取得對應的方向的route\n",
    "            updatelog(file = logfile, text = '[info]: ====== Start:開始拆分路線 ======')\n",
    "            updatelog(file = logfile, text = f'[info]: route:{route} / direction:{direction}')\n",
    "            # print(\"\\n\\n=====Start=====\")\n",
    "            # print(f\"route {route}\" )\n",
    "            # print(f\"direction {direction}\")\n",
    "            # print(\"======\")\n",
    "            busroute_select = busroute[ (busroute[route_id_col] == route) & (busroute[route_direction_col] == direction)][[route_id_col,route_direction_col,'geometry' ]].reset_index(drop = True)\n",
    "            # 也要有對應的seq\n",
    "            seq_select = seq[ (seq[seq_id_col] == route) & (seq[seq_direction_col] == direction) ].sort_values(seq_seq_col).reset_index(drop = True)\n",
    "            seq_select['geometry'] = seq_select.apply(lambda row: Point(row[seq_lng_col], row[seq_lat_col]), axis=1)\n",
    "            # 將seq_select從 Pandas DataFrame 轉換為 GeoDataFrame\n",
    "            seq_select = gpd.GeoDataFrame(seq_select, geometry='geometry').drop_duplicates(subset=[seq_seq_col]).reset_index(drop = True)\n",
    "            seq_select = seq_select.set_crs(epsg=4326, inplace=True)\n",
    "            if len(seq_select) > 0: \n",
    "                # print(f\"seq_select_{route}_{direction}:\", end=\"　\")\n",
    "                # print(len(seq_select))\n",
    "                updatelog(file = logfile, text = f'[info]: 符合的站序共有:{len(seq_select):,}個點位')\n",
    "                original_gdfseq.append(seq_select)\n",
    "                original_gdfroute.append(busroute_select)\n",
    "                \n",
    "\n",
    "                # 01_將公車站序點位投影到路線上\n",
    "                updatelog(file = logfile, text = f'[info]: 站序投影')\n",
    "                gdf_snapstop_select = snap_points_to_line(seq_select, \n",
    "                                                          busroute_select,\n",
    "                                                          route_id_col='SubRouteUID',\n",
    "                                                          route_direction_col='Direction',\n",
    "                                                          seq_id_col='SubRouteUID',\n",
    "                                                          seq_direction_col='Direction',\n",
    "                                                          seq_lat_col='PositionLat',\n",
    "                                                          seq_lng_col='PositionLon')\n",
    "                if len (gdf_snapstop_select) > 0 :\n",
    "                    gdf_snappoints.append(gdf_snapstop_select)\n",
    "\n",
    "\n",
    "                # 02_將路線進行拆分\n",
    "                updatelog(file = logfile, text = f'[info]: 路線開始拆分')\n",
    "                gdf_routesegment_select = split_routes(busroute_select, \n",
    "                                                    seq_select,\n",
    "                                                    route_id_col='SubRouteUID',\n",
    "                                                    route_direction_col='Direction',\n",
    "                                                    seq_id_col='SubRouteUID',\n",
    "                                                    seq_direction_col='Direction',\n",
    "                                                    seq_seq_col='StopSequence', \n",
    "                                                    seq_lat_col='PositionLat',\n",
    "                                                    seq_lng_col='PositionLon')\n",
    "                \n",
    "                updatelog(file = logfile, text = f'[info]: 拆分後的路段有:{len(gdf_routesegment_select):,}筆路段')\n",
    "\n",
    "                if len(seq_select) -1 != len(gdf_routesegment_select):\n",
    "                    updatelog(file = logfile, text = f'[info]: {route}_{direction} 的路段數量有問題')\n",
    "\n",
    "                if len (gdf_routesegment_select) > 0 :\n",
    "                    gdf_snappoints.append(gdf_snapstop_select)                \n",
    "                    gdf_routesegment_select = gdf_routesegment_select.set_crs(epsg=4326, inplace=True)\n",
    "                    gdf_segment_routes.append(gdf_routesegment_select)\n",
    "\n",
    "print(len(gdf_snappoints))\n",
    "if len(gdf_snappoints) > 0 : \n",
    "    gdf_snappoints = pd.concat(gdf_snappoints)\n",
    "    gdf_snappoints.to_file(os.path.join(outputfolder, 'SnappedSequence.shp'))\n",
    "    updatelog(file = logfile, text = f'[info]: gdf_snappoints 輸出成功')\n",
    "\n",
    "if len(original_gdfseq) > 0 : \n",
    "    original_gdfseq = pd.concat(original_gdfseq)\n",
    "    original_gdfseq.to_file(os.path.join(outputfolder, 'original_gdfseq.shp'))\n",
    "    updatelog(file = logfile, text = f'[info]: original_gdfseq 輸出成功')\n",
    "\n",
    "if len(original_gdfroute) > 0 : \n",
    "    original_gdfroute = pd.concat(original_gdfroute)\n",
    "    original_gdfroute.to_file(os.path.join(outputfolder, 'original_gdfroute.shp'))\n",
    "    updatelog(file = logfile, text = f'[info]: original_gdfroute 輸出成功')\n",
    "\n",
    "if len(gdf_segment_routes) > 0 : \n",
    "    gdf_segment_routes = pd.concat(gdf_segment_routes)\n",
    "    gdf_segment_routes_line = gdf_segment_routes[gdf_segment_routes.geometry.type.isin(['LineString', 'MultiLineString'])]\n",
    "    gdf_segment_routes_line.to_file(os.path.join(outputfolder, 'gdf_segment_routes.shp'))\n",
    "    updatelog(file = logfile, text = f'[info]: gdf_segment_routes 輸出成功')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
