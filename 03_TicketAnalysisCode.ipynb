{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51662c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "from collections import Counter   # 用來方便累加每個 chunk 的統計結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873ae102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00_setup_os處理函數\n",
    "def create_folder(folder_name):\n",
    "    \"\"\"建立資料夾\"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return os.path.abspath(folder_name)\n",
    "\n",
    "def findfiles(filefolderpath, filetype='.csv', recursive=True):\n",
    "    \"\"\"\n",
    "    尋找指定路徑下指定類型的檔案，並返回檔案路徑列表。\n",
    "\n",
    "    Args:\n",
    "        filefolderpath (str): 指定的檔案路徑。\n",
    "        filetype (str, optional): 要尋找的檔案類型，預設為 '.csv'。\n",
    "        recursive (bool, optional): 是否檢索所有子資料夾，預設為 True；反之為False，僅查找當前資料夾的所有file。\n",
    "\n",
    "    Returns:\n",
    "        list: 包含所有符合條件的檔案路徑的列表。\n",
    "    \"\"\"\n",
    "    filelist = []\n",
    "\n",
    "    if recursive:\n",
    "        # 遍歷資料夾及其子資料夾\n",
    "        for root, _, files in os.walk(filefolderpath):\n",
    "            for file in files:\n",
    "                if file.endswith(filetype):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    filelist.append(file_path)\n",
    "    else:\n",
    "        # 僅檢索當前資料夾\n",
    "        for file in os.listdir(filefolderpath):\n",
    "            file_path = os.path.join(filefolderpath, file)\n",
    "            if os.path.isfile(file_path) and file.endswith(filetype):\n",
    "                filelist.append(file_path)\n",
    "\n",
    "    return filelist\n",
    "\n",
    "def read_combined_dataframe(file_list, filepath = True):\n",
    "    dataframes = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        try:\n",
    "            if file.endswith('.csv'):\n",
    "                df = pd.read_csv(file)\n",
    "            elif file.endswith('.shp'):\n",
    "                df = gpd.read_file(file)\n",
    "            elif file.endswith(('.xls', '.xlsx')):\n",
    "                df = pd.read_excel(file)\n",
    "            else:\n",
    "                print(f\"Unsupported file format: {file}\")\n",
    "                continue\n",
    "            if filepath:\n",
    "                df['FilePath'] = file  # 添加來源檔案路徑欄位\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    # 合併所有 DataFrame\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# 01_資料預處理\n",
    "def filter_ticket_data(filepath, \n",
    "                       selectdate_start, \n",
    "                       selectdate_end, \n",
    "                       outputfolder,\n",
    "                       skiprows=1, \n",
    "                       chunksize=1000,\n",
    "                        on_time_column = 'BoardingTime', \n",
    "                       off_time_column = 'DeboardingTime', \n",
    "                       infodate_column = 'InfoDate',):\n",
    "    \"\"\"\n",
    "    分批讀取大型票證 CSV，依上車時間欄位做日期篩選後輸出新的 CSV。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        原始 CSV 路徑\n",
    "    on_time_column : str\n",
    "        上車時間欄位名稱\n",
    "    off_time_column : str\n",
    "        下車時間欄位名稱（保留未來擴充）\n",
    "    selectdate_start : str\n",
    "        篩選起始日期（YYYY-MM-DD）\n",
    "    selectdate_end : str\n",
    "        篩選結束日期（YYYY-MM-DD）\n",
    "    outputfolder : str\n",
    "        最終輸出 CSV 的資料夾路徑\n",
    "    skiprows : int\n",
    "        讀取 CSV 時跳過的列\n",
    "    chunksize : int\n",
    "        每批讀取筆數\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    outputpath : str\n",
    "        最終輸出 CSV 的完整路徑\n",
    "    \"\"\"\n",
    "\n",
    "    # 建立輸出資料夾（如不存在）\n",
    "    os.makedirs(outputfolder, exist_ok=True)\n",
    "\n",
    "    # 產生輸出檔名\n",
    "    filename = os.path.basename(filepath).replace(\n",
    "        \".csv\", f\"_{selectdate_start}_to_{selectdate_end}.csv\"\n",
    "    )\n",
    "    outputpath = os.path.join(outputfolder, filename)\n",
    "\n",
    "    # 日期轉 datetime\n",
    "    start = pd.to_datetime(selectdate_start)\n",
    "    end   = pd.to_datetime(selectdate_end)\n",
    "\n",
    "    # 分批讀取\n",
    "    chunks = pd.read_csv(filepath, skiprows=skiprows, chunksize=chunksize)\n",
    "    first_chunk = True\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # 轉成 datetime\n",
    "        # chunk[on_time_column] = pd.to_datetime(chunk[on_time_column], errors='coerce')\n",
    "        # chunk[off_time_column] = pd.to_datetime(chunk[off_time_column], errors='coerce')\n",
    "        chunk[infodate_column] = pd.to_datetime(chunk[infodate_column], errors='coerce')\n",
    "\n",
    "        # 日期篩選\n",
    "        # mask = (\n",
    "        #     ((chunk[on_time_column]  >= start) & (chunk[on_time_column]  <= end)) |\n",
    "        #     ((chunk[off_time_column] >= start) & (chunk[off_time_column] <= end))\n",
    "        # )    \n",
    "        # mask = (chunk[on_time_column] >= start) & (chunk[on_time_column] <= end)\n",
    "        mask = (chunk[infodate_column] >= start) & (chunk[infodate_column] <= end)\n",
    "        filtered_chunk = chunk[mask]\n",
    "\n",
    "        if filtered_chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # 寫入 CSV\n",
    "        filtered_chunk.to_csv(\n",
    "            outputpath,\n",
    "            mode='w' if first_chunk else 'a',\n",
    "            header=first_chunk,\n",
    "            index=False,\n",
    "            encoding='utf-8-sig'\n",
    "        )\n",
    "        first_chunk = False\n",
    "\n",
    "    return outputpath\n",
    "\n",
    "# def tickets_cleaning(\n",
    "#     tickets, \n",
    "#     on_time_column='on_time_column', \n",
    "#     off_time_column='off_time_column', \n",
    "#     getonstop='GetOnStop', \n",
    "#     getoffstop='GetOffStop', \n",
    "#     getonseq='GetOnSeq', \n",
    "#     getoffseq='GetOffSeq'):\n",
    "#     \"\"\"\n",
    "#     清理票證資料，篩選出符合條件的票證並輸出統計結果。\n",
    "#     可以用於檢查票證資料的正確性。\n",
    "#     \"\"\"\n",
    "#     # 原始票證數量\n",
    "#     original_count = len(tickets)\n",
    "\n",
    "#     # 建立篩選條件\n",
    "#     valid_conditions = (\n",
    "#         (tickets[on_time_column] < tickets[off_time_column]) &  # 上車時間早於下車時間\n",
    "#         (tickets[getonstop] != tickets[getoffstop]) &  # 上下車站不同\n",
    "#         (tickets[getonseq] < tickets[getoffseq])  # 上下車序正確\n",
    "#     )\n",
    "\n",
    "#     # 檢查每個條件的異常數量\n",
    "#     late_count = (tickets[on_time_column] > tickets[off_time_column]).sum()\n",
    "#     same_stop_count = (tickets[getonstop] == tickets[getoffstop]).sum()\n",
    "#     seq_error_count = (tickets[getonseq] >= tickets[getoffseq]).sum()\n",
    "    \n",
    "\n",
    "#     # 篩選出符合條件的票證\n",
    "#     cleaned_tickets = tickets[valid_conditions]\n",
    "#     canuse_count = len(cleaned_tickets)\n",
    "\n",
    "#     # 統計結果\n",
    "#     output = {\n",
    "#         '原始票證數量': original_count,\n",
    "#         '資料正常':canuse_count, \n",
    "#         '資料異常 - 上車晚於下車': late_count,\n",
    "#         '資料異常 - 同站上下車': same_stop_count,\n",
    "#         '資料異常 - 上下車次序錯誤': seq_error_count\n",
    "#     }\n",
    "\n",
    "#     correctrate = round((canuse_count / original_count) * 100, 1)\n",
    "#     return cleaned_tickets, output, correctrate\n",
    "\n",
    "def tickets_cleaning(\n",
    "    tickets,\n",
    "    on_time_column='BoardingTime',\n",
    "    off_time_column='DeboardingTime',\n",
    "    getonstop='BoardingStopUID',\n",
    "    getoffstop='DeboardingStopUID',\n",
    "    getonseq='BoardingStopSequence',\n",
    "    getoffseq='DeboardingStopSequence'):\n",
    "\n",
    "    n = len(tickets)\n",
    "\n",
    "    # ---- 型別轉換（你不把缺值當異常，但比較要正確）----\n",
    "    on_time  = pd.to_datetime(tickets[on_time_column], errors='coerce')\n",
    "    off_time = pd.to_datetime(tickets[off_time_column], errors='coerce')\n",
    "    on_seq   = pd.to_numeric(tickets[getonseq], errors='coerce')\n",
    "    off_seq  = pd.to_numeric(tickets[getoffseq], errors='coerce')\n",
    "    on_stop  = tickets[getonstop]\n",
    "    off_stop = tickets[getoffstop]\n",
    "\n",
    "    # ---- 能確定的三種異常（缺值不算異常）----\n",
    "    m_time_rev  = (on_time > off_time)               # 上車晚於下車\n",
    "    m_same_stop = (on_stop == off_stop)              # 同站上下車\n",
    "    m_seq_err   = (on_seq >= off_seq)                # 上序 >= 下序\n",
    "\n",
    "    # ---- 資料正常（只有確定異常才算異常，其餘都正常）----\n",
    "    m_ok = ~(m_time_rev | m_same_stop | m_seq_err)\n",
    "\n",
    "    cleaned = tickets[m_ok].copy()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # ⭐⭐ 依你的要求：新增 ErrorMsg 欄位，描述缺哪些資料（但不當異常）\n",
    "    # ---------------------------------------------------------\n",
    "    miss_off_time = off_time.isna()\n",
    "    miss_off_stop = off_stop.isna()\n",
    "\n",
    "    def combine_err(row):\n",
    "        msgs = []\n",
    "        if row['miss_off_time']:\n",
    "            msgs.append(\"沒有下車刷卡時間\")\n",
    "        if row['miss_off_stop']:\n",
    "            msgs.append(\"沒有下車站點資料\")\n",
    "        return \"；\".join(msgs)\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        \"miss_off_time\": miss_off_time,\n",
    "        \"miss_off_stop\": miss_off_stop\n",
    "    })\n",
    "\n",
    "    cleaned[\"ErrorMsg\"] = temp_df.loc[cleaned.index].apply(combine_err, axis=1)\n",
    "    # 若沒有錯誤，改成空字串\n",
    "    cleaned[\"ErrorMsg\"] = cleaned[\"ErrorMsg\"].replace(\"\", \"\")\n",
    "\n",
    "    # ---- 統計輸出 ----\n",
    "    output = {\n",
    "        '原始票證數量': int(n),\n",
    "        '資料正常': int(m_ok.sum()),\n",
    "        '資料異常 - 上車晚於下車': int(m_time_rev.sum()),\n",
    "        '資料異常 - 同站上下車': int(m_same_stop.sum()),\n",
    "        '資料異常 - 上下車次序錯誤': int(m_seq_err.sum()),\n",
    "        # 額外統計（可選）：缺哪些資料\n",
    "        '資訊缺失 - 沒有下車刷卡時間': int(miss_off_time.sum()),\n",
    "        '資訊缺失 - 沒有下車站點資料': int(miss_off_stop.sum())\n",
    "    }\n",
    "\n",
    "    correctrate = round((output['資料正常'] / n) * 100, 2) if n else 0.0\n",
    "    return cleaned, output, correctrate\n",
    "\n",
    "def mark_ticket_errors(\n",
    "    tickets, \n",
    "    on_time_column='on_time_column', \n",
    "    off_time_column='off_time_column', \n",
    "    getonstop='GetOnStop', \n",
    "    getoffstop='GetOffStop', \n",
    "    getonseq='GetOnSeq', \n",
    "    getoffseq='GetOffSeq'):\n",
    "    \"\"\"\n",
    "    在票證資料上貼三種錯誤標籤，為 0/1。\n",
    "    不做篩選，不刪資料，只新增欄位。\n",
    "    \"\"\"\n",
    "    tickets['error_time'] = (tickets[on_time_column] > tickets[off_time_column]).astype(int)\n",
    "    tickets['error_same_stop'] = (tickets[getonstop] == tickets[getoffstop]).astype(int)\n",
    "    tickets['error_seq'] = (tickets[getonseq] >= tickets[getoffseq]).astype(int)\n",
    "\n",
    "    tickets['error'] = (\n",
    "        (tickets['error_time'] == 1) |\n",
    "        (tickets['error_same_stop'] == 1) |\n",
    "        (tickets['error_seq'] == 1)\n",
    "    ).astype(int)\n",
    "\n",
    "    return tickets\n",
    "\n",
    "def export_ticketcorrectrate(filename, output, correctrate, txt_path):\n",
    "\n",
    "    # 運算時間\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # 判斷檔案是否已存在\n",
    "    file_exists = os.path.exists(txt_path)\n",
    "\n",
    "    # 若檔案不存在 → 用 w (寫入 header)\n",
    "    # 若檔案存在 → 用 a (不寫 header)\n",
    "    mode = \"a\" if file_exists else \"w\"\n",
    "\n",
    "    with open(txt_path, mode, encoding=\"utf-8\") as f:\n",
    "\n",
    "        # 如果是新檔案，寫入 header\n",
    "        if not file_exists:\n",
    "            f.write(\"filename,timestamp,key,value\\n\")\n",
    "\n",
    "        # 寫入 output 每筆資料\n",
    "        for key, value in output.items():\n",
    "            f.write(f\"{filename},{timestamp},{key},{value}\\n\")\n",
    "\n",
    "        # 寫入正確率\n",
    "        f.write(f\"{filename},{timestamp},正確率,{correctrate}\\n\")\n",
    "\n",
    "    print(f\"TXT (CSV 格式) 已輸出：{txt_path}\")\n",
    "\n",
    "def get_stop_fromtickets(df):\n",
    "    \"\"\"\n",
    "    從票證資料中提取所有上下車站點資訊，並合併成一個包含所有站點的 DataFrame。\n",
    "    用於檢查票種的站點是否為可用的站點，因為有站點才有辦法核對到GIS。\n",
    "    \n",
    "    參數:\n",
    "    df (DataFrame): 包含票證資料的 DataFrame，需包含上下車站點相關欄位。\n",
    "    \n",
    "    回傳:\n",
    "    DataFrame: 包含所有上下車站點資訊的 DataFrame。\n",
    "    \"\"\"\n",
    "    \n",
    "     # 選取需要的欄位\n",
    "    select_columns = ['Authority', 'OperatorNo',  \n",
    "                    'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', 'Direction']\n",
    "    boarding_stop_columns = ['BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence']\n",
    "    deboarding_stop_columns = ['DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence']\n",
    "\n",
    "    # 取上車資料\n",
    "    dfboarding =  df[select_columns + boarding_stop_columns]\n",
    "    dfboarding[select_columns + boarding_stop_columns] = dfboarding[select_columns + boarding_stop_columns].fillna('-99')\n",
    "    dfboarding.columns = dfboarding.columns.str.replace('Boarding', '')\n",
    "    dfboarding['OnorOff'] = 'On'\n",
    "\n",
    "    # 取下車資料\n",
    "    dfdeboarding =  df[select_columns + deboarding_stop_columns]\n",
    "    dfdeboarding[select_columns + deboarding_stop_columns] = dfdeboarding[select_columns+ deboarding_stop_columns].fillna('-99')\n",
    "    dfdeboarding.columns = dfdeboarding.columns.str.replace('Deboarding', '')\n",
    "    dfdeboarding['OnorOff'] = 'Off'\n",
    "    # 合併上下車站點資料\n",
    "    df_stops = pd.concat([dfboarding, dfdeboarding], ignore_index=True)\n",
    "    \n",
    "    df_stops = (\n",
    "        df_stops\n",
    "        .fillna(-99)\n",
    "        .groupby(df_stops.columns.tolist())\n",
    "        .size()\n",
    "        .reset_index(name='Count')\n",
    "    )\n",
    "\n",
    "    return df_stops\n",
    "\n",
    "def match_stop_coordinates(\n",
    "    dfstop, \n",
    "    stop_gdf, \n",
    "    col_uid=\"StopUID\", \n",
    "    col_name=\"StopName\", \n",
    "    col_lat=\"Lat\", \n",
    "    col_lon=\"Lon\"):\n",
    "    \"\"\"\n",
    "    進行兩階段站點比對，並將所有原本 print 的文字改成 text 文字回傳：\n",
    "    回傳：\n",
    "        dfcount_final : 二階段比對後結果 DataFrame\n",
    "        text : 報表文字（取代 print）\n",
    "    \"\"\"\n",
    "\n",
    "    text_output = []\n",
    "\n",
    "    # 第一次比對：比對 StopUID 與 StopName\n",
    "    dfcount = pd.merge(\n",
    "        dfstop,\n",
    "        stop_gdf[[col_uid, col_name, col_lon, col_lat]].drop_duplicates(subset=[col_uid, col_name]),\n",
    "        on=[col_uid, col_name],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    total = dfstop[\"Count\"].sum()\n",
    "    abnormal = dfcount[(dfcount[col_lon].isna()) | (dfcount[col_lat].isna())][\"Count\"].sum()\n",
    "\n",
    "    text_output.append(\"第一次比對結果\")\n",
    "    text_output.append(f\"總共有幾筆資料: {total:,}\")\n",
    "    text_output.append(f\"沒有對應經緯度座標的資料異常數量: {abnormal:,}\")\n",
    "    text_output.append(f\"影響比例: {abnormal / total:.4%}\")\n",
    "    text_output.append(\"============================\")\n",
    "\n",
    "    # 第二次比對：只比對 StopUID\n",
    "    dfcount_2ndround = dfcount[(dfcount[col_lon].isna()) | (dfcount[col_lat].isna())].copy()\n",
    "\n",
    "    dfcount_2ndround = pd.merge(\n",
    "        dfcount_2ndround.drop(columns=[col_lon, col_lat]),\n",
    "        stop_gdf[[col_uid, col_lon, col_lat, col_name]].drop_duplicates(subset=[col_uid]),\n",
    "        on=[col_uid],\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_gdf\")\n",
    "    )\n",
    "\n",
    "    total_2ndround = dfcount_2ndround[\"Count\"].sum()\n",
    "    abnormal_2ndround = dfcount_2ndround[(dfcount_2ndround[col_lon].isna()) | (dfcount_2ndround[col_lat].isna())][\"Count\"].sum()\n",
    "\n",
    "    text_output.append(\"第二次比對結果\")\n",
    "    text_output.append(f\"第二次比對 - 總共有幾筆資料: {total_2ndround:,}\")\n",
    "    text_output.append(f\"第二次比對 - 沒有對應經緯度座標的資料異常數量: {abnormal_2ndround:,}\")\n",
    "    text_output.append(f\"第二次比對 - 影響比例: {abnormal_2ndround / total_2ndround:.4%}\")\n",
    "    text_output.append(f\"第二次比對 - 影響佔可用票證的原始比例: {abnormal_2ndround / total:.4%}\")\n",
    "    text_output.append(\"============================\")\n",
    "\n",
    "    # 最終合併：第一次成功 + 第二次比對結果\n",
    "    dfcount_final = pd.concat(\n",
    "        [dfcount[~((dfcount[col_lon].isna()) | (dfcount[col_lat].isna()))], \n",
    "         dfcount_2ndround],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # 將文字合成一個字串\n",
    "    text = \"\\n\".join(text_output)\n",
    "\n",
    "    return dfcount_final, text\n",
    "\n",
    "\n",
    "# 02_資料分析處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1428724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00_Setup 所有全域函數\n",
    "\n",
    "# 1.) 設定篩選日期區間\n",
    "selectdate_start = '2024-10-01'\n",
    "selectdate_end = '2024-11-30'\n",
    "\n",
    "# 2.) 建立輸出資料夾\n",
    "selecttime_ticket_folder = create_folder(os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '01_指定時間區間票證資料')) # 建立01-01 指定時間區間票證資料夾\n",
    "checkok_ticketfolder = create_folder(os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '02_過濾可用票證資料')) # 建立01-02 過濾可用票證資料夾\n",
    "check_stopfolder = create_folder(os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '03_所有使用到的點位')) # 建立01-03 所有使用到的點位資料夾\n",
    "reformat_folder = create_folder(os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '04_計算交通量格式')) # 建立01-03 所有使用到的點位資料夾\n",
    "\n",
    "hourlycount_folder = create_folder(os.path.join(os.getcwd(), '..', '02_初步分析', '01_分時計次')) # 建立01-03 所有使用到的點位資料夾\n",
    "dailybetweenstops_folder = create_folder(os.path.join(os.getcwd(), '..', '02_初步分析', '02_全日站間量'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b02f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理01: 指定時間區間票證資料切分\n",
    "def pre01_split_ticket_with_day(selectdate_start, selectdate_end, outputfolder):\n",
    "        orginal_ticket_files = [\n",
    "                                r'D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\2024_2025\\公路客運電子票證資料(TO1A)\\公路客運電子票證資料(TO1A).csv', \n",
    "                                r'D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\2024_2025\\新北市公車電子票證資料(TO1A)\\新北市公車電子票證資料(TO1A).csv', \n",
    "                                r'D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\2024_2025\\桃園市公車電子票證資料(TO1A)\\桃園市公車電子票證資料(TO1A).csv', \n",
    "                                ]\n",
    "        for file in orginal_ticket_files:\n",
    "                output = filter_ticket_data(\n",
    "                        filepath = file,\n",
    "                        infodate_column = 'InfoDate',\n",
    "                        selectdate_start = selectdate_start,\n",
    "                        selectdate_end = selectdate_end,\n",
    "                        outputfolder = outputfolder,\n",
    "                        skiprows = 1,\n",
    "                        chunksize = 1000\n",
    "                        )\n",
    "                print(\"輸出路徑：\", output)\n",
    "\n",
    "# pre01_split_ticket_with_day(selectdate_start, selectdate_end, selecttime_ticket_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 額外處理 -> 為了找到是否有問題的\n",
    "marked_ticketfolder = create_folder(\n",
    "    os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '01-01_指定時間區間票證資料_但有錯誤標記')\n",
    ")\n",
    "\n",
    "selecttime_ticket_files = findfiles(selecttime_ticket_folder, filetype='.csv', recursive=False)\n",
    "selecttime_ticket_files = [f for f in selecttime_ticket_files if 'TO1' in f]\n",
    "\n",
    "for file in selecttime_ticket_files:\n",
    "    marked_output_file = os.path.join(\n",
    "        marked_ticketfolder,\n",
    "        os.path.basename(file).replace(\".csv\", \"_marked.csv\")\n",
    "    )\n",
    "\n",
    "    # 如果 mark_ticket_errors 需要全表上下文，改成 chunksize=None\n",
    "    reader = pd.read_csv(file, chunksize=1000)\n",
    "\n",
    "    first_chunk = True\n",
    "    for chunk in reader:\n",
    "        output = mark_ticket_errors(\n",
    "            tickets=chunk, \n",
    "            on_time_column='BoardingTime',\n",
    "            off_time_column='DeboardingTime',\n",
    "            getonstop='BoardingStopUID',\n",
    "            getoffstop='DeboardingStopUID',\n",
    "            getonseq='BoardingStopSequence',\n",
    "            getoffseq='DeboardingStopSequence'\n",
    "        )\n",
    "\n",
    "        output.to_csv(\n",
    "            marked_output_file,\n",
    "            mode='w' if first_chunk else 'a',\n",
    "            header=first_chunk,\n",
    "            index=False,\n",
    "            encoding='utf-8-sig'\n",
    "        )\n",
    "        first_chunk = False  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d92724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理02: 指定時間區間票證資料切分\n",
    "def pre02_get_correct_tickets(selecttime_ticket_folder, checkok_ticketfolder):\n",
    "\n",
    "    selecttime_ticket_files = findfiles(selecttime_ticket_folder, filetype='.csv', recursive=False)\n",
    "    correctratelog_path = os.path.join(checkok_ticketfolder, '客運票證資料正確率記錄.txt')\n",
    "\n",
    "    chunksize = 10000   \n",
    "\n",
    "    for file in selecttime_ticket_files:\n",
    "\n",
    "        print(f\"\\n=== 開始處理：{file} ===\")\n",
    "\n",
    "        # 統計資料累加器\n",
    "        total_stat = Counter()\n",
    "\n",
    "        # 輸出清洗後 CSV 的路徑\n",
    "        cleaned_output_path = os.path.join(\n",
    "            checkok_ticketfolder,\n",
    "            os.path.basename(file).replace(\".csv\", \"_cleaned.csv\")\n",
    "        )\n",
    "\n",
    "        first_chunk = True  # 控制 header\n",
    "\n",
    "        # 分批讀取整個檔案\n",
    "        for chunk in pd.read_csv(file, chunksize=chunksize, encoding='utf-8-sig'):\n",
    "\n",
    "            # 跑你自己的清洗函數\n",
    "            cleaned_df, correct_stat_info, correctrate_chunk = tickets_cleaning(\n",
    "                chunk,\n",
    "                on_time_column='BoardingTime',\n",
    "                off_time_column='DeboardingTime',\n",
    "                getonstop='BoardingStopUID',\n",
    "                getoffstop='DeboardingStopUID',\n",
    "                getonseq='BoardingStopSequence',\n",
    "                getoffseq='DeboardingStopSequence'\n",
    "            )\n",
    "\n",
    "            # 累加統計\n",
    "            total_stat.update(correct_stat_info)\n",
    "\n",
    "            # 將清洗後的 cleaned_df 分批寫入新 CSV\n",
    "            if not cleaned_df.empty:\n",
    "                cleaned_df.to_csv(\n",
    "                    cleaned_output_path,\n",
    "                    mode='w' if first_chunk else 'a',\n",
    "                    header=first_chunk,\n",
    "                    index=False,\n",
    "                    encoding='utf-8-sig'\n",
    "                )\n",
    "                first_chunk = False\n",
    "\n",
    "        # -------- 整份 CSV 的整體正確率 --------\n",
    "        original_count = total_stat.get('原始票證數量', 0)\n",
    "        canuse_count   = total_stat.get('資料正常', 0)\n",
    "\n",
    "        if original_count > 0:\n",
    "            final_correctrate = round(canuse_count / original_count * 100, 2)\n",
    "        else:\n",
    "            final_correctrate = 0.0\n",
    "\n",
    "        # -------- 寫入 TXT（CSV 格式） --------\n",
    "        export_ticketcorrectrate(\n",
    "            filename=file,\n",
    "            output=dict(total_stat),\n",
    "            correctrate=final_correctrate,\n",
    "            txt_path=correctratelog_path\n",
    "        )\n",
    "\n",
    "        print(f\"清洗後資料輸出：{cleaned_output_path}\")\n",
    "\n",
    "# pre02_get_correct_tickets(selecttime_ticket_folder, checkok_ticketfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f70d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理03: 確認所有站點的經緯度在TDX都可以被核對出來\n",
    "\n",
    "def pre03_findstops(checkok_ticketfolder, \n",
    "                    seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\"):\n",
    "\n",
    "    files = findfiles(checkok_ticketfolder)\n",
    "    files = [f for f in files if 'TO1' in f]\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, encoding='utf-8-sig')\n",
    "        stop = get_stop_fromtickets(df)\n",
    "        stop['file_source'] = os.path.basename(file)\n",
    "\n",
    "        outputfilename = os.path.join(check_stopfolder, os.path.basename(file).replace('_cleaned.csv', '_stops.csv'))\n",
    "        stop.to_csv(outputfilename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"站點資料輸出：{outputfilename}\")\n",
    "\n",
    "    df_stop = read_combined_dataframe(findfiles(check_stopfolder, filetype='csv', recursive=False), filepath=False)\n",
    "\n",
    "    df_seq = read_combined_dataframe(findfiles(seqfolder, \n",
    "                                            filetype='csv', \n",
    "                                            recursive=False), filepath=False)\n",
    "    df_stopfromseq = df_seq[['StopUID', 'StopName_Zh', 'PositionLon', 'PositionLat']].drop_duplicates(subset=['StopUID']).sort_values(['StopUID'])\n",
    "\n",
    "    df_final, report_text = match_stop_coordinates(\n",
    "        dfstop=df_stop.copy().rename(columns = {'StopName':'StopName_Zh'}),\n",
    "        stop_gdf=df_stopfromseq,\n",
    "        col_uid=\"StopUID\",\n",
    "        col_name=\"StopName_Zh\",\n",
    "        col_lat=\"PositionLat\",\n",
    "        col_lon=\"PositionLon\"\n",
    "    )\n",
    "\n",
    "    print(report_text)\n",
    "\n",
    "\n",
    "\n",
    "    # a = df_final[((df_final['PositionLon'].isna()) | (df_final['PositionLat'].isna())) & (df_final['StopUID'] != \"-99\")][['StopUID', 'StopName_Zh']].drop_duplicates()\n",
    "    # a['Auth'] = a['StopUID'].str[:3]\n",
    "    # a.sort_values(['Auth'])\n",
    "\n",
    "# pre03_findstops(checkok_ticketfolder, seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daecf5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理04: 加上必要欄位 (平假日欄位、刪除不重要的欄位）\n",
    "\n",
    "def add_weekdayandweekendcolumns(df, \n",
    "                                 timecolumns='InfoDate',\n",
    "                                 filterdate=None):\n",
    "    \"\"\"\n",
    "    將 DataFrame 中的時間欄位轉換為日期時間格式，新增 DaysofWeek 和 WDWK 欄位，\n",
    "    並可選擇性地過濾掉特定日期。\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 原始 DataFrame。\n",
    "        timecolumns (str): 包含日期的欄位名稱，預設為 'InfoDate'。\n",
    "        filterdate (list/None): 要過濾掉的日期字串列表 (例如 ['YYYY-MM-DD'])。\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 處理後的 DataFrame。\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. 將時間欄位轉換為 datetime\n",
    "    df[timecolumns] = pd.to_datetime(df[timecolumns], errors='coerce')\n",
    "\n",
    "    # 2. 新增 'DaysofWeek' 欄位\n",
    "    \n",
    "    df['DaysofWeek'] = df[timecolumns].dt.dayofweek # .dt.dayofweek 會回傳：0=週一, 1=週二, ..., 6=週日\n",
    "\n",
    "    # 3. 處理過濾日期 (如果 filterdate 不是 None 且有內容)\n",
    "    if filterdate and len(filterdate) > 0:\n",
    "        # 將 filterdate 列表轉換為 datetime 格式，以便進行比較\n",
    "        filter_dates_dt = pd.to_datetime(filterdate)\n",
    "        \n",
    "        # 找出不在 filter_dates_dt 中的日期 (布林遮罩)\n",
    "        # .dt.normalize() 將日期時間的時間部分設為 00:00:00，確保只比較日期\n",
    "        filter_mask = ~df[timecolumns].dt.normalize().isin(filter_dates_dt)\n",
    "        \n",
    "        # 套用遮罩，只保留不在過濾列表中的資料\n",
    "        df = df[filter_mask].copy()\n",
    "\n",
    "    # 4. 新增 'WDWK' 欄位\n",
    "    # .dt.dayofweek 回傳：0=週一, 1=週二, 2=週三, 3=週四, 4=週五, 5=週六, 6=週日\n",
    "    \n",
    "    # 定義條件：\n",
    "    # WDWK = 1 (週二=1, 週三=2, 週四=3)\n",
    "    wdwk_1_condition = df['DaysofWeek'].isin([1, 2, 3])\n",
    "    \n",
    "    # WDWK = -1 (週六=5, 週日=6)\n",
    "    wdwk_neg1_condition = df['DaysofWeek'].isin([5, 6])\n",
    "    \n",
    "    # 使用 np.select (比多個 if/elif 判斷更快)\n",
    "    \n",
    "    df['WDWK'] = np.select(\n",
    "        [wdwk_1_condition, wdwk_neg1_condition], # 條件列表\n",
    "        [1, -1],                                # 對應的值\n",
    "        default=0                               # 預設值 (其他日子=0)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def must_outputformat(df):\n",
    "    df['BoardingTime'] = pd.to_datetime(df['BoardingTime'], errors='coerce')\n",
    "    df['DeboardingTime'] = pd.to_datetime(df['DeboardingTime'], errors='coerce')\n",
    "    df['BoardinngDate'] = df['BoardingTime'].dt.date\n",
    "    df['DeboardingDate'] = df['DeboardingTime'].dt.date\n",
    "    df['BoardingHour'] = df['BoardingTime'].dt.hour\n",
    "    df['DeboardingHour'] = df['DeboardingTime'].dt.hour\n",
    "\n",
    "    reindexcolumns = ['Authority', 'OperatorNo', 'HolderType', 'TicketType', 'SubTicketType', \n",
    "                    'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', 'Direction', \n",
    "                    'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence', 'BoardinngDate',  'BoardingHour', \n",
    "                    'DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence', 'DeboardingDate', 'DeboardingHour',\n",
    "                    'InfoDate', 'DaysofWeek', 'WDWK']\n",
    "\n",
    "    df = df.reindex(columns=reindexcolumns)\n",
    "    return df \n",
    "\n",
    "def pre04_reformat(checkok_ticketfolder, reformat_folder):\n",
    "\n",
    "    filelist = findfiles(checkok_ticketfolder, filetype='csv', recursive=False)\n",
    "\n",
    "    for file in filelist:\n",
    "\n",
    "        reformat_output_file = os.path.join(\n",
    "            reformat_folder,\n",
    "            os.path.basename(file).replace(\"_cleaned.csv\", \"_reformatted.csv\")\n",
    "        )\n",
    "\n",
    "\n",
    "        # 如果 mark_ticket_errors 需要全表上下文，改成 chunksize=None\n",
    "        reader = pd.read_csv(file, chunksize=1000)\n",
    "\n",
    "        first_chunk = True\n",
    "        for chunk in reader:\n",
    "\n",
    "            output = add_weekdayandweekendcolumns(df=chunk,\n",
    "                                            timecolumns= 'InfoDate', \n",
    "                                            filterdate= ['2024-10-09', '2024-10-10', '2024-10-11', '2024-10-12', '2024-10-13', '2024-10-14', '2024-10-15'])\n",
    "            output = must_outputformat(output)\n",
    "\n",
    "            output.to_csv(\n",
    "                reformat_output_file,\n",
    "                mode='w' if first_chunk else 'a',\n",
    "                header=first_chunk,\n",
    "                index=False,\n",
    "                encoding='utf-8-sig'\n",
    "            )\n",
    "            first_chunk = False  \n",
    "\n",
    "pre04_reformat(checkok_ticketfolder, reformat_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = findfiles(checkok_ticketfolder, filetype='csv', recursive=False)\n",
    "\n",
    "for file in filelist:\n",
    "\n",
    "    reformat_output_file = os.path.join(\n",
    "        reformat_folder,\n",
    "        os.path.basename(file).replace(\"_cleaned.csv\", \"_reformatted.csv\")\n",
    "    )\n",
    "\n",
    "\n",
    "    # 如果 mark_ticket_errors 需要全表上下文，改成 chunksize=None\n",
    "    reader = pd.read_csv(file, chunksize=1000)\n",
    "\n",
    "    first_chunk = True\n",
    "    for chunk in reader:\n",
    "\n",
    "        output = add_weekdayandweekendcolumns(df=chunk,\n",
    "                                        timecolumns= 'InfoDate', \n",
    "                                        filterdate= ['2024-10-09', '2024-10-10', '2024-10-11', '2024-10-12', '2024-10-13', '2024-10-14', '2024-10-15'])\n",
    "        output = must_outputformat(output)\n",
    "\n",
    "        output.to_csv(\n",
    "            reformat_output_file,\n",
    "            mode='w' if first_chunk else 'a',\n",
    "            header=first_chunk,\n",
    "            index=False,\n",
    "            encoding='utf-8-sig'\n",
    "        )\n",
    "        first_chunk = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7122013e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authority</th>\n",
       "      <th>OperatorNo</th>\n",
       "      <th>HolderType</th>\n",
       "      <th>TicketType</th>\n",
       "      <th>SubTicketType</th>\n",
       "      <th>RouteUID</th>\n",
       "      <th>RouteName</th>\n",
       "      <th>SubRouteUID</th>\n",
       "      <th>SubRouteName</th>\n",
       "      <th>Direction</th>\n",
       "      <th>...</th>\n",
       "      <th>BoardinngDate</th>\n",
       "      <th>BoardingHour</th>\n",
       "      <th>DeboardingStopUID</th>\n",
       "      <th>DeboardingStopName</th>\n",
       "      <th>DeboardingStopSequence</th>\n",
       "      <th>DeboardingDate</th>\n",
       "      <th>DeboardingHour</th>\n",
       "      <th>InfoDate</th>\n",
       "      <th>DaysofWeek</th>\n",
       "      <th>WDWK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NewTaipei</td>\n",
       "      <td>301</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>#NOR-1200</td>\n",
       "      <td>NWT18258</td>\n",
       "      <td>712副</td>\n",
       "      <td>NWT160167</td>\n",
       "      <td>712副</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>16</td>\n",
       "      <td>NWT221599</td>\n",
       "      <td>迴龍派出所</td>\n",
       "      <td>28</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>16</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NewTaipei</td>\n",
       "      <td>301</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NWT16515</td>\n",
       "      <td>858</td>\n",
       "      <td>NWT157550</td>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>12</td>\n",
       "      <td>NWT131311</td>\n",
       "      <td>泰山區公所</td>\n",
       "      <td>37</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NewTaipei</td>\n",
       "      <td>301</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>#NOR-1200</td>\n",
       "      <td>NWT18119</td>\n",
       "      <td>967</td>\n",
       "      <td>NWT159907</td>\n",
       "      <td>967體育大學行政教學大樓</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>14</td>\n",
       "      <td>NWT203915</td>\n",
       "      <td>空間樂園社區</td>\n",
       "      <td>40</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>15</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NewTaipei</td>\n",
       "      <td>301</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NWT10474</td>\n",
       "      <td>636</td>\n",
       "      <td>NWT10474</td>\n",
       "      <td>636</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>20</td>\n",
       "      <td>NWT10566</td>\n",
       "      <td>捷運新莊站(新莊郵局)</td>\n",
       "      <td>20</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewTaipei</td>\n",
       "      <td>301</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>#NOR-1200</td>\n",
       "      <td>NWT16591</td>\n",
       "      <td>857</td>\n",
       "      <td>NWT157639</td>\n",
       "      <td>857</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>17</td>\n",
       "      <td>NWT139066</td>\n",
       "      <td>菜寮(重新路)</td>\n",
       "      <td>65</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>18</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Authority  OperatorNo HolderType  TicketType SubTicketType  RouteUID  \\\n",
       "0  NewTaipei         301          A           4     #NOR-1200  NWT18258   \n",
       "1  NewTaipei         301          B           1           NaN  NWT16515   \n",
       "2  NewTaipei         301          A           4     #NOR-1200  NWT18119   \n",
       "3  NewTaipei         301          A           1           NaN  NWT10474   \n",
       "4  NewTaipei         301          A           4     #NOR-1200  NWT16591   \n",
       "\n",
       "  RouteName SubRouteUID   SubRouteName  Direction  ... BoardinngDate  \\\n",
       "0      712副   NWT160167           712副          1  ...    2024-10-01   \n",
       "1       858   NWT157550            858          0  ...    2024-10-01   \n",
       "2       967   NWT159907  967體育大學行政教學大樓          1  ...    2024-10-01   \n",
       "3       636    NWT10474            636          1  ...    2024-10-01   \n",
       "4       857   NWT157639            857          0  ...    2024-10-01   \n",
       "\n",
       "  BoardingHour  DeboardingStopUID DeboardingStopName  DeboardingStopSequence  \\\n",
       "0           16          NWT221599              迴龍派出所                      28   \n",
       "1           12          NWT131311              泰山區公所                      37   \n",
       "2           14          NWT203915             空間樂園社區                      40   \n",
       "3           20           NWT10566        捷運新莊站(新莊郵局)                      20   \n",
       "4           17          NWT139066            菜寮(重新路)                      65   \n",
       "\n",
       "  DeboardingDate DeboardingHour   InfoDate DaysofWeek  WDWK  \n",
       "0     2024-10-01             16 2024-10-01          1     1  \n",
       "1     2024-10-01             12 2024-10-01          1     1  \n",
       "2     2024-10-01             15 2024-10-01          1     1  \n",
       "3     2024-10-01             21 2024-10-01          1     1  \n",
       "4     2024-10-01             18 2024-10-01          1     1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8655461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6279df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析01: 確認資料各票種、各路線、平假日、起點、迄點筆數\n",
    "\n",
    "def analytics01_hourlycount(checkok_ticketfolder, \n",
    "                            hourlycount_folder, \n",
    "                            seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\",\n",
    "                            returndf = True):\n",
    "\n",
    "    files = findfiles(checkok_ticketfolder)\n",
    "    files = [f for f in files if 'TO1' in f]\n",
    "    df = read_combined_dataframe(files)\n",
    "    df['BoardingTime'] = pd.to_datetime(df['BoardingTime'], errors='coerce')\n",
    "    df['DeboardingTime'] = pd.to_datetime(df['DeboardingTime'], errors='coerce')\n",
    "    df['BoardinngDate'] = df['BoardingTime'].dt.date\n",
    "    df['DeboardingDate'] = df['DeboardingTime'].dt.date\n",
    "    df['BoardingHour'] = df['BoardingTime'].dt.hour\n",
    "    df['DeboardingHour'] = df['DeboardingTime'].dt.hour\n",
    "\n",
    "    groupbycolumns = ['HolderType', \n",
    "                    'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName',\n",
    "                    'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence', 'BoardinngDate', 'BoardingHour',\n",
    "                    'DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence', 'DeboardingDate', 'DeboardingHour', 'FilePath']\n",
    "\n",
    "    df[groupbycolumns] = df[groupbycolumns].fillna('-99')\n",
    "    df_count = df.groupby(groupbycolumns).size().reset_index(name='Count')\n",
    "\n",
    "    df_seq = read_combined_dataframe(findfiles(seqfolder, \n",
    "                                            filetype='csv', \n",
    "                                            recursive=False), filepath=False)\n",
    "    df_stopfromseq = df_seq[['StopUID', 'StopName_Zh', 'PositionLon', 'PositionLat']].drop_duplicates(subset=['StopUID']).sort_values(['StopUID'])\n",
    "\n",
    "    df_count = pd.merge(df_count, \n",
    "                        df_stopfromseq[['StopUID', 'PositionLon', 'PositionLat']].rename(columns = {'StopUID':'BoardingStopUID', 'PositionLon':'BoardingLon', 'PositionLat':'BoardingLat'}), \n",
    "                        on = 'BoardingStopUID', \n",
    "                        how='left')\n",
    "\n",
    "    df_count = pd.merge(df_count, \n",
    "                        df_stopfromseq[['StopUID', 'PositionLon', 'PositionLat']].rename(columns = {'StopUID':'DeboardingStopUID', 'PositionLon':'DeboardingLon', 'PositionLat':'DeboardingLat'}), \n",
    "                        on = 'DeboardingStopUID', \n",
    "                        how='left')\n",
    "    df_count = df_count.reindex(columns= ['HolderType', 'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', \n",
    "                                        'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence','BoardinngDate', 'BoardingHour', 'BoardingLon', 'BoardingLat', \n",
    "                                        'DeboardingStopUID','DeboardingStopName', 'DeboardingStopSequence', 'DeboardingDate', 'DeboardingHour', 'DeboardingLon', 'DeboardingLat', \n",
    "                                        'FilePath', 'Count'])\n",
    "\n",
    "    outputfile = os.path.join(hourlycount_folder, '上下車區分票種分時計次.csv')\n",
    "    df_count.to_csv(outputfile, index=False)\n",
    "\n",
    "    if returndf:\n",
    "        return df_count\n",
    "\n",
    "analytics01_hourlycount(checkok_ticketfolder, \n",
    "                        hourlycount_folder, \n",
    "                        seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\", \n",
    "                        returndf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279989ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
