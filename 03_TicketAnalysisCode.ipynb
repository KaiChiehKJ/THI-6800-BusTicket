{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51662c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "from collections import Counter   # 用來方便累加每個 chunk 的統計結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e2aaea",
   "metadata": {},
   "source": [
    "# finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ae102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00_setup_os處理函數\n",
    "def create_folder(folder_name):\n",
    "    \"\"\"建立資料夾\"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return os.path.abspath(folder_name)\n",
    "\n",
    "def findfiles(filefolderpath, filetype='.csv', recursive=True):\n",
    "    \"\"\"\n",
    "    尋找指定路徑下指定類型的檔案，並返回檔案路徑列表。\n",
    "\n",
    "    Args:\n",
    "        filefolderpath (str): 指定的檔案路徑。\n",
    "        filetype (str, optional): 要尋找的檔案類型，預設為 '.csv'。\n",
    "        recursive (bool, optional): 是否檢索所有子資料夾，預設為 True；反之為False，僅查找當前資料夾的所有file。\n",
    "\n",
    "    Returns:\n",
    "        list: 包含所有符合條件的檔案路徑的列表。\n",
    "    \"\"\"\n",
    "    filelist = []\n",
    "\n",
    "    if recursive:\n",
    "        # 遍歷資料夾及其子資料夾\n",
    "        for root, _, files in os.walk(filefolderpath):\n",
    "            for file in files:\n",
    "                if file.endswith(filetype):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    filelist.append(file_path)\n",
    "    else:\n",
    "        # 僅檢索當前資料夾\n",
    "        for file in os.listdir(filefolderpath):\n",
    "            file_path = os.path.join(filefolderpath, file)\n",
    "            if os.path.isfile(file_path) and file.endswith(filetype):\n",
    "                filelist.append(file_path)\n",
    "\n",
    "    return filelist\n",
    "\n",
    "def read_combined_dataframe(file_list, filepath = True):\n",
    "    dataframes = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        try:\n",
    "            if file.endswith('.csv'):\n",
    "                df = pd.read_csv(file)\n",
    "            elif file.endswith('.shp'):\n",
    "                df = gpd.read_file(file)\n",
    "            elif file.endswith(('.xls', '.xlsx')):\n",
    "                df = pd.read_excel(file)\n",
    "            else:\n",
    "                print(f\"Unsupported file format: {file}\")\n",
    "                continue\n",
    "            if filepath:\n",
    "                df['FilePath'] = file  # 添加來源檔案路徑欄位\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    # 合併所有 DataFrame\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# 01_資料預處理\n",
    "def filter_ticket_data(filepath, \n",
    "                       selectdate_start, \n",
    "                       selectdate_end, \n",
    "                       outputfolder,\n",
    "                       skiprows=1, \n",
    "                       chunksize=1000,\n",
    "                        on_time_column = 'BoardingTime', \n",
    "                       off_time_column = 'DeboardingTime', \n",
    "                       infodate_column = 'InfoDate',):\n",
    "    \"\"\"\n",
    "    分批讀取大型票證 CSV，依上車時間欄位做日期篩選後輸出新的 CSV。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        原始 CSV 路徑\n",
    "    on_time_column : str\n",
    "        上車時間欄位名稱\n",
    "    off_time_column : str\n",
    "        下車時間欄位名稱（保留未來擴充）\n",
    "    selectdate_start : str\n",
    "        篩選起始日期（YYYY-MM-DD）\n",
    "    selectdate_end : str\n",
    "        篩選結束日期（YYYY-MM-DD）\n",
    "    outputfolder : str\n",
    "        最終輸出 CSV 的資料夾路徑\n",
    "    skiprows : int\n",
    "        讀取 CSV 時跳過的列\n",
    "    chunksize : int\n",
    "        每批讀取筆數\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    outputpath : str\n",
    "        最終輸出 CSV 的完整路徑\n",
    "    \"\"\"\n",
    "\n",
    "    # 建立輸出資料夾（如不存在）\n",
    "    os.makedirs(outputfolder, exist_ok=True)\n",
    "\n",
    "    # 產生輸出檔名\n",
    "    filename = os.path.basename(filepath).replace(\n",
    "        \".csv\", f\"_{selectdate_start}_to_{selectdate_end}.csv\"\n",
    "    )\n",
    "    outputpath = os.path.join(outputfolder, filename)\n",
    "\n",
    "    # 日期轉 datetime\n",
    "    start = pd.to_datetime(selectdate_start)\n",
    "    end   = pd.to_datetime(selectdate_end)\n",
    "\n",
    "    # 分批讀取\n",
    "    chunks = pd.read_csv(filepath, skiprows=skiprows, chunksize=chunksize)\n",
    "    first_chunk = True\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # 轉成 datetime\n",
    "        # chunk[on_time_column] = pd.to_datetime(chunk[on_time_column], errors='coerce')\n",
    "        # chunk[off_time_column] = pd.to_datetime(chunk[off_time_column], errors='coerce')\n",
    "        chunk[infodate_column] = pd.to_datetime(chunk[infodate_column], errors='coerce')\n",
    "\n",
    "        # 日期篩選\n",
    "        # mask = (\n",
    "        #     ((chunk[on_time_column]  >= start) & (chunk[on_time_column]  <= end)) |\n",
    "        #     ((chunk[off_time_column] >= start) & (chunk[off_time_column] <= end))\n",
    "        # )    \n",
    "        # mask = (chunk[on_time_column] >= start) & (chunk[on_time_column] <= end)\n",
    "        mask = (chunk[infodate_column] >= start) & (chunk[infodate_column] <= end)\n",
    "        filtered_chunk = chunk[mask]\n",
    "\n",
    "        if filtered_chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # 寫入 CSV\n",
    "        filtered_chunk.to_csv(\n",
    "            outputpath,\n",
    "            mode='w' if first_chunk else 'a',\n",
    "            header=first_chunk,\n",
    "            index=False,\n",
    "            encoding='utf-8-sig'\n",
    "        )\n",
    "        first_chunk = False\n",
    "\n",
    "    return outputpath\n",
    "\n",
    "# def tickets_cleaning(\n",
    "#     tickets, \n",
    "#     on_time_column='on_time_column', \n",
    "#     off_time_column='off_time_column', \n",
    "#     getonstop='GetOnStop', \n",
    "#     getoffstop='GetOffStop', \n",
    "#     getonseq='GetOnSeq', \n",
    "#     getoffseq='GetOffSeq'):\n",
    "#     \"\"\"\n",
    "#     清理票證資料，篩選出符合條件的票證並輸出統計結果。\n",
    "#     可以用於檢查票證資料的正確性。\n",
    "#     \"\"\"\n",
    "#     # 原始票證數量\n",
    "#     original_count = len(tickets)\n",
    "\n",
    "#     # 建立篩選條件\n",
    "#     valid_conditions = (\n",
    "#         (tickets[on_time_column] < tickets[off_time_column]) &  # 上車時間早於下車時間\n",
    "#         (tickets[getonstop] != tickets[getoffstop]) &  # 上下車站不同\n",
    "#         (tickets[getonseq] < tickets[getoffseq])  # 上下車序正確\n",
    "#     )\n",
    "\n",
    "#     # 檢查每個條件的異常數量\n",
    "#     late_count = (tickets[on_time_column] > tickets[off_time_column]).sum()\n",
    "#     same_stop_count = (tickets[getonstop] == tickets[getoffstop]).sum()\n",
    "#     seq_error_count = (tickets[getonseq] >= tickets[getoffseq]).sum()\n",
    "    \n",
    "\n",
    "#     # 篩選出符合條件的票證\n",
    "#     cleaned_tickets = tickets[valid_conditions]\n",
    "#     canuse_count = len(cleaned_tickets)\n",
    "\n",
    "#     # 統計結果\n",
    "#     output = {\n",
    "#         '原始票證數量': original_count,\n",
    "#         '資料正常':canuse_count, \n",
    "#         '資料異常 - 上車晚於下車': late_count,\n",
    "#         '資料異常 - 同站上下車': same_stop_count,\n",
    "#         '資料異常 - 上下車次序錯誤': seq_error_count\n",
    "#     }\n",
    "\n",
    "#     correctrate = round((canuse_count / original_count) * 100, 1)\n",
    "#     return cleaned_tickets, output, correctrate\n",
    "\n",
    "def tickets_cleaning(\n",
    "    tickets,\n",
    "    on_time_column='BoardingTime',\n",
    "    off_time_column='DeboardingTime',\n",
    "    getonstop='BoardingStopUID',\n",
    "    getoffstop='DeboardingStopUID',\n",
    "    getonseq='BoardingStopSequence',\n",
    "    getoffseq='DeboardingStopSequence'):\n",
    "\n",
    "    n = len(tickets)\n",
    "\n",
    "    # ---- 型別轉換（你不把缺值當異常，但比較要正確）----\n",
    "    on_time  = pd.to_datetime(tickets[on_time_column], errors='coerce')\n",
    "    off_time = pd.to_datetime(tickets[off_time_column], errors='coerce')\n",
    "    on_seq   = pd.to_numeric(tickets[getonseq], errors='coerce')\n",
    "    off_seq  = pd.to_numeric(tickets[getoffseq], errors='coerce')\n",
    "    on_stop  = tickets[getonstop]\n",
    "    off_stop = tickets[getoffstop]\n",
    "\n",
    "    # ---- 能確定的三種異常（缺值不算異常）----\n",
    "    m_time_rev  = (on_time > off_time)               # 上車晚於下車\n",
    "    m_same_stop = (on_stop == off_stop)              # 同站上下車\n",
    "    # m_seq_err   = (on_seq >= off_seq)                # 上序 >= 下序\n",
    "\n",
    "    # ---- 資料正常（只有確定異常才算異常，其餘都正常）----\n",
    "    # m_ok = ~(m_time_rev | m_same_stop | m_seq_err)\n",
    "    m_ok = ~(m_time_rev | m_same_stop )\n",
    "\n",
    "    cleaned = tickets[m_ok].copy()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 依你的要求：新增 ErrorMsg 欄位，描述缺哪些資料（但不當異常）\n",
    "    # ---------------------------------------------------------\n",
    "    miss_off_time = off_time.isna()\n",
    "    miss_off_stop = off_stop.isna()\n",
    "\n",
    "    def combine_err(row):\n",
    "        msgs = []\n",
    "        if row['miss_off_time']:\n",
    "            msgs.append(\"沒有下車刷卡時間\")\n",
    "        if row['miss_off_stop']:\n",
    "            msgs.append(\"沒有下車站點資料\")\n",
    "        return \"；\".join(msgs)\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        \"miss_off_time\": miss_off_time,\n",
    "        \"miss_off_stop\": miss_off_stop\n",
    "    })\n",
    "\n",
    "    cleaned[\"ErrorMsg\"] = temp_df.loc[cleaned.index].apply(combine_err, axis=1)\n",
    "    # 若沒有錯誤，改成空字串\n",
    "    cleaned[\"ErrorMsg\"] = cleaned[\"ErrorMsg\"].replace(\"\", \"\")\n",
    "\n",
    "    # ---- 統計輸出 ----\n",
    "    output = {\n",
    "        '原始票證數量': int(n),\n",
    "        '資料正常': int(m_ok.sum()),\n",
    "        '資料異常 - 上車晚於下車': int(m_time_rev.sum()),\n",
    "        '資料異常 - 同站上下車': int(m_same_stop.sum()),\n",
    "        # '資料異常 - 上下車次序錯誤': int(m_seq_err.sum()),\n",
    "        '資訊缺失 - 沒有下車刷卡時間': int(miss_off_time.sum()),\n",
    "        '資訊缺失 - 沒有下車站點資料': int(miss_off_stop.sum())\n",
    "    }\n",
    "\n",
    "    correctrate = round((output['資料正常'] / n) * 100, 2) if n else 0.0\n",
    "    return cleaned, output, correctrate\n",
    "\n",
    "def mark_ticket_errors(\n",
    "    tickets, \n",
    "    on_time_column='on_time_column', \n",
    "    off_time_column='off_time_column', \n",
    "    getonstop='GetOnStop', \n",
    "    getoffstop='GetOffStop', \n",
    "    getonseq='GetOnSeq', \n",
    "    getoffseq='GetOffSeq'):\n",
    "    \"\"\"\n",
    "    在票證資料上貼三種錯誤標籤，為 0/1。\n",
    "    不做篩選，不刪資料，只新增欄位。\n",
    "    \"\"\"\n",
    "    tickets['error_time'] = (tickets[on_time_column] > tickets[off_time_column]).astype(int)\n",
    "    tickets['error_same_stop'] = (tickets[getonstop] == tickets[getoffstop]).astype(int)\n",
    "    # tickets['error_seq'] = (tickets[getonseq] >= tickets[getoffseq]).astype(int)\n",
    "\n",
    "    # 判斷各欄是否為無效值（NaN、-99、\"-99\"）\n",
    "    tickets['error_onseq']  = (\n",
    "        tickets[getonseq].isin([-99, \"-99\"]) | tickets[getonseq].isna()\n",
    "    ).astype(int)\n",
    "\n",
    "    tickets['error_offseq'] = (\n",
    "        tickets[getoffseq].isin([-99, \"-99\"]) | tickets[getoffseq].isna()\n",
    "    ).astype(int)\n",
    "\n",
    "\n",
    "    tickets['error'] = (\n",
    "        (tickets['error_time'] == 1) |\n",
    "        (tickets['error_same_stop'] == 1) |\n",
    "        (tickets['error_onseq'] == 1) | \n",
    "        (tickets['error_offseq'] == 1)\n",
    "    ).astype(int)\n",
    "\n",
    "    return tickets\n",
    "\n",
    "def export_ticketcorrectrate(filename, output, correctrate, txt_path):\n",
    "\n",
    "    # 運算時間\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # 判斷檔案是否已存在\n",
    "    file_exists = os.path.exists(txt_path)\n",
    "\n",
    "    # 若檔案不存在 → 用 w (寫入 header)\n",
    "    # 若檔案存在 → 用 a (不寫 header)\n",
    "    mode = \"a\" if file_exists else \"w\"\n",
    "\n",
    "    with open(txt_path, mode, encoding=\"utf-8\") as f:\n",
    "\n",
    "        # 如果是新檔案，寫入 header\n",
    "        if not file_exists:\n",
    "            f.write(\"filename,timestamp,key,value\\n\")\n",
    "\n",
    "        # 寫入 output 每筆資料\n",
    "        for key, value in output.items():\n",
    "            f.write(f\"{filename},{timestamp},{key},{value}\\n\")\n",
    "\n",
    "        # 寫入正確率\n",
    "        f.write(f\"{filename},{timestamp},正確率,{correctrate}\\n\")\n",
    "\n",
    "    print(f\"TXT (CSV 格式) 已輸出：{txt_path}\")\n",
    "\n",
    "def get_stop_fromtickets(df):\n",
    "    \"\"\"\n",
    "    從票證資料中提取所有上下車站點資訊，並合併成一個包含所有站點的 DataFrame。\n",
    "    用於檢查票種的站點是否為可用的站點，因為有站點才有辦法核對到GIS。\n",
    "    \n",
    "    參數:\n",
    "    df (DataFrame): 包含票證資料的 DataFrame，需包含上下車站點相關欄位。\n",
    "    \n",
    "    回傳:\n",
    "    DataFrame: 包含所有上下車站點資訊的 DataFrame。\n",
    "    \"\"\"\n",
    "    \n",
    "     # 選取需要的欄位\n",
    "    select_columns = ['Authority', 'OperatorNo',  \n",
    "                    'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', 'Direction']\n",
    "    boarding_stop_columns = ['BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence']\n",
    "    deboarding_stop_columns = ['DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence']\n",
    "\n",
    "    # 取上車資料\n",
    "    dfboarding =  df[select_columns + boarding_stop_columns]\n",
    "    dfboarding[select_columns + boarding_stop_columns] = dfboarding[select_columns + boarding_stop_columns].fillna('-99')\n",
    "    dfboarding.columns = dfboarding.columns.str.replace('Boarding', '')\n",
    "    dfboarding['OnorOff'] = 'On'\n",
    "\n",
    "    # 取下車資料\n",
    "    dfdeboarding =  df[select_columns + deboarding_stop_columns]\n",
    "    dfdeboarding[select_columns + deboarding_stop_columns] = dfdeboarding[select_columns+ deboarding_stop_columns].fillna('-99')\n",
    "    dfdeboarding.columns = dfdeboarding.columns.str.replace('Deboarding', '')\n",
    "    dfdeboarding['OnorOff'] = 'Off'\n",
    "    # 合併上下車站點資料\n",
    "    df_stops = pd.concat([dfboarding, dfdeboarding], ignore_index=True)\n",
    "    \n",
    "    df_stops = (\n",
    "        df_stops\n",
    "        .fillna(-99)\n",
    "        .groupby(df_stops.columns.tolist())\n",
    "        .size()\n",
    "        .reset_index(name='Count')\n",
    "    )\n",
    "\n",
    "    return df_stops\n",
    "\n",
    "def match_stop_coordinates(\n",
    "    dfstop, \n",
    "    stop_gdf, \n",
    "    col_uid=\"StopUID\", \n",
    "    col_name=\"StopName\", \n",
    "    col_lat=\"Lat\", \n",
    "    col_lon=\"Lon\"):\n",
    "    \"\"\"\n",
    "    進行兩階段站點比對，並將所有原本 print 的文字改成 text 文字回傳：\n",
    "    回傳：\n",
    "        dfcount_final : 二階段比對後結果 DataFrame\n",
    "        text : 報表文字（取代 print）\n",
    "    \"\"\"\n",
    "\n",
    "    text_output = []\n",
    "\n",
    "    # 第一次比對：比對 StopUID 與 StopName\n",
    "    dfcount = pd.merge(\n",
    "        dfstop,\n",
    "        stop_gdf[[col_uid, col_name, col_lon, col_lat]].drop_duplicates(subset=[col_uid, col_name]),\n",
    "        on=[col_uid, col_name],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    total = dfstop[\"Count\"].sum()\n",
    "    abnormal = dfcount[(dfcount[col_lon].isna()) | (dfcount[col_lat].isna())][\"Count\"].sum()\n",
    "\n",
    "    text_output.append(\"第一次比對結果\")\n",
    "    text_output.append(f\"總共有幾筆資料: {total:,}\")\n",
    "    text_output.append(f\"沒有對應經緯度座標的資料異常數量: {abnormal:,}\")\n",
    "    text_output.append(f\"影響比例: {abnormal / total:.4%}\")\n",
    "    text_output.append(\"============================\")\n",
    "\n",
    "    # 第二次比對：只比對 StopUID\n",
    "    dfcount_2ndround = dfcount[(dfcount[col_lon].isna()) | (dfcount[col_lat].isna())].copy()\n",
    "\n",
    "    dfcount_2ndround = pd.merge(\n",
    "        dfcount_2ndround.drop(columns=[col_lon, col_lat]),\n",
    "        stop_gdf[[col_uid, col_lon, col_lat, col_name]].drop_duplicates(subset=[col_uid]),\n",
    "        on=[col_uid],\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_gdf\")\n",
    "    )\n",
    "\n",
    "    total_2ndround = dfcount_2ndround[\"Count\"].sum()\n",
    "    abnormal_2ndround = dfcount_2ndround[(dfcount_2ndround[col_lon].isna()) | (dfcount_2ndround[col_lat].isna())][\"Count\"].sum()\n",
    "\n",
    "    text_output.append(\"第二次比對結果\")\n",
    "    text_output.append(f\"第二次比對 - 總共有幾筆資料: {total_2ndround:,}\")\n",
    "    text_output.append(f\"第二次比對 - 沒有對應經緯度座標的資料異常數量: {abnormal_2ndround:,}\")\n",
    "    text_output.append(f\"第二次比對 - 影響比例: {abnormal_2ndround / total_2ndround:.4%}\")\n",
    "    text_output.append(f\"第二次比對 - 影響佔可用票證的原始比例: {abnormal_2ndround / total:.4%}\")\n",
    "    text_output.append(\"============================\")\n",
    "\n",
    "    # 最終合併：第一次成功 + 第二次比對結果\n",
    "    dfcount_final = pd.concat(\n",
    "        [dfcount[~((dfcount[col_lon].isna()) | (dfcount[col_lat].isna()))], \n",
    "         dfcount_2ndround],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # 將文字合成一個字串\n",
    "    text = \"\\n\".join(text_output)\n",
    "\n",
    "    return dfcount_final, text\n",
    "\n",
    "# 02_資料分析處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1428724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00_Setup 所有全域函數\n",
    "\n",
    "# 1.) 設定篩選日期區間\n",
    "selectdate_start = '2024-10-01'\n",
    "selectdate_end = '2024-11-30'\n",
    "\n",
    "# 2.) 資料input資料夾\n",
    "\n",
    "\n",
    "# 3.) 建立輸出資料夾\n",
    "selecttime_ticket_folder = create_folder(os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '01_指定時間區間票證資料')) # 建立01-01 指定時間區間票證資料夾\n",
    "checkok_ticketfolder = create_folder(os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '02_過濾可用票證資料')) # 建立01-02 過濾可用票證資料夾\n",
    "check_stopfolder = create_folder(os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '03_所有使用到的點位')) # 建立01-03 所有使用到的點位資料夾\n",
    "reformat_folder = create_folder(os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '04_計算交通量格式')) # 建立01-03 所有使用到的點位資料夾\n",
    "correctseq_folder = create_folder(os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '05_重新處理票證站序')) # 建立01-03 所有使用到的點位資料夾\n",
    "\n",
    "hourlycount_folder = create_folder(os.path.join(os.getcwd(), '..', '02_初步分析', '01_分時計次')) # 建立01-03 所有使用到的點位資料夾\n",
    "dailybetweenstops_folder = create_folder(os.path.join(os.getcwd(), '..', '02_初步分析', '02_全日站間量'))\n",
    "od_folder = create_folder(os.path.join(os.getcwd(), '..', '02_初步分析', '03_OD起迄量'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b02f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理01: 指定時間區間票證資料切分\n",
    "def pre01_split_ticket_with_day(selectdate_start, selectdate_end, outputfolder):\n",
    "        orginal_ticket_files = [\n",
    "                                r'D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\2024_2025\\公路客運電子票證資料(TO1A)\\公路客運電子票證資料(TO1A).csv', \n",
    "                                # r'D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\2024_2025\\新北市公車電子票證資料(TO1A)\\新北市公車電子票證資料(TO1A).csv', \n",
    "                                # r'D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\2024_2025\\桃園市公車電子票證資料(TO1A)\\桃園市公車電子票證資料(TO1A).csv', \n",
    "                                ]\n",
    "        for file in orginal_ticket_files:\n",
    "                output = filter_ticket_data(\n",
    "                        filepath = file,\n",
    "                        infodate_column = 'InfoDate',\n",
    "                        selectdate_start = selectdate_start,\n",
    "                        selectdate_end = selectdate_end,\n",
    "                        outputfolder = outputfolder,\n",
    "                        skiprows = 1,\n",
    "                        chunksize = 1000\n",
    "                        )\n",
    "                print(\"輸出路徑：\", output)\n",
    "\n",
    "# pre01_split_ticket_with_day(selectdate_start, selectdate_end, selecttime_ticket_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f39bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 額外處理 -> 為了找到是否有問題的\n",
    "# marked_ticketfolder = create_folder(\n",
    "#     os.path.join(os.getcwd(), '..', '01_初步篩選整理票證', '01-01_指定時間區間票證資料_但有錯誤標記')\n",
    "# )\n",
    "\n",
    "# selecttime_ticket_files = findfiles(selecttime_ticket_folder, filetype='.csv', recursive=False)\n",
    "# selecttime_ticket_files = [f for f in selecttime_ticket_files if 'TO1' in f]\n",
    "\n",
    "# for file in selecttime_ticket_files:\n",
    "#     marked_output_file = os.path.join(\n",
    "#         marked_ticketfolder,\n",
    "#         os.path.basename(file).replace(\".csv\", \"_marked.csv\")\n",
    "#     )\n",
    "\n",
    "#     cleaned_output_file = os.path.join(\n",
    "#         checkok_ticketfolder,\n",
    "#         os.path.basename(file).replace(\".csv\", \"_cleaned.csv\")\n",
    "#     )\n",
    "\n",
    "#     # 如果 mark_ticket_errors 需要全表上下文，改成 chunksize=None\n",
    "#     reader = pd.read_csv(file, chunksize=1000)\n",
    "\n",
    "#     first_chunk = True\n",
    "#     for chunk in reader:\n",
    "#         output = mark_ticket_errors(\n",
    "#             tickets=chunk, \n",
    "#             on_time_column='BoardingTime',\n",
    "#             off_time_column='DeboardingTime',\n",
    "#             getonstop='BoardingStopUID',\n",
    "#             getoffstop='DeboardingStopUID',\n",
    "#             getonseq='BoardingStopSequence',\n",
    "#             getoffseq='DeboardingStopSequence'\n",
    "#         )\n",
    "\n",
    "#         output.to_csv(\n",
    "#             marked_output_file,\n",
    "#             mode='w' if first_chunk else 'a',\n",
    "#             header=first_chunk,\n",
    "#             index=False,\n",
    "#             encoding='utf-8-sig'\n",
    "#         )\n",
    "\n",
    "#         output[output['error'] != 1].drop(columns = ['error_time', 'error_same_stop', 'error_onseq', 'error_offseq', 'error']).to_csv()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         first_chunk = False  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d92724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理02: 過濾不合理票證資料(用站序資料\n",
    "def pre02_get_correct_tickets(selecttime_ticket_folder, checkok_ticketfolder):\n",
    "\n",
    "    selecttime_ticket_files = findfiles(selecttime_ticket_folder, filetype='.csv', recursive=False)\n",
    "    correctratelog_path = os.path.join(checkok_ticketfolder, '客運票證資料正確率記錄.txt')\n",
    "\n",
    "    chunksize = 10000   \n",
    "\n",
    "    for file in selecttime_ticket_files:\n",
    "\n",
    "        print(f\"\\n=== 開始處理：{file} ===\")\n",
    "\n",
    "        # 統計資料累加器\n",
    "        total_stat = Counter()\n",
    "\n",
    "        # 輸出清洗後 CSV 的路徑\n",
    "        cleaned_output_path = os.path.join(\n",
    "            checkok_ticketfolder,\n",
    "            os.path.basename(file).replace(\".csv\", \"_cleaned.csv\")\n",
    "        )\n",
    "\n",
    "        first_chunk = True  # 控制 header\n",
    "\n",
    "        # 分批讀取整個檔案\n",
    "        for chunk in pd.read_csv(file, chunksize=chunksize, encoding='utf-8-sig'):\n",
    "\n",
    "            # 跑你自己的清洗函數\n",
    "            cleaned_df, correct_stat_info, correctrate_chunk = tickets_cleaning(\n",
    "                chunk,\n",
    "                on_time_column='BoardingTime',\n",
    "                off_time_column='DeboardingTime',\n",
    "                getonstop='BoardingStopUID',\n",
    "                getoffstop='DeboardingStopUID',\n",
    "                getonseq='BoardingStopSequence',\n",
    "                getoffseq='DeboardingStopSequence'\n",
    "            )\n",
    "\n",
    "            # 累加統計\n",
    "            total_stat.update(correct_stat_info)\n",
    "\n",
    "            # 將清洗後的 cleaned_df 分批寫入新 CSV\n",
    "            if not cleaned_df.empty:\n",
    "                cleaned_df.to_csv(\n",
    "                    cleaned_output_path,\n",
    "                    mode='w' if first_chunk else 'a',\n",
    "                    header=first_chunk,\n",
    "                    index=False,\n",
    "                    encoding='utf-8-sig'\n",
    "                )\n",
    "                first_chunk = False\n",
    "\n",
    "        # -------- 整份 CSV 的整體正確率 --------\n",
    "        original_count = total_stat.get('原始票證數量', 0)\n",
    "        canuse_count   = total_stat.get('資料正常', 0)\n",
    "\n",
    "        if original_count > 0:\n",
    "            final_correctrate = round(canuse_count / original_count * 100, 2)\n",
    "        else:\n",
    "            final_correctrate = 0.0\n",
    "\n",
    "        # -------- 寫入 TXT（CSV 格式） --------\n",
    "        export_ticketcorrectrate(\n",
    "            filename=file,\n",
    "            output=dict(total_stat),\n",
    "            correctrate=final_correctrate,\n",
    "            txt_path=correctratelog_path\n",
    "        )\n",
    "\n",
    "        print(f\"清洗後資料輸出：{cleaned_output_path}\")\n",
    "\n",
    "# pre02_get_correct_tickets(selecttime_ticket_folder, checkok_ticketfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f70d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理03: 確認所有站點的經緯度在TDX都可以被核對出來\n",
    "\n",
    "def pre03_findstops(checkok_ticketfolder, \n",
    "                    seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\"):\n",
    "\n",
    "    files = findfiles(checkok_ticketfolder)\n",
    "    files = [f for f in files if 'TO1' in f]\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, encoding='utf-8-sig')\n",
    "        stop = get_stop_fromtickets(df)\n",
    "        stop['file_source'] = os.path.basename(file)\n",
    "\n",
    "        outputfilename = os.path.join(check_stopfolder, os.path.basename(file).replace('_cleaned.csv', '_stops.csv'))\n",
    "        stop.to_csv(outputfilename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"站點資料輸出：{outputfilename}\")\n",
    "\n",
    "    df_stop = read_combined_dataframe(findfiles(check_stopfolder, filetype='csv', recursive=False), filepath=False)\n",
    "\n",
    "    df_seq = read_combined_dataframe(findfiles(seqfolder, \n",
    "                                            filetype='csv', \n",
    "                                            recursive=False), filepath=False)\n",
    "    df_stopfromseq = df_seq[['StopUID', 'StopName_Zh', 'PositionLon', 'PositionLat']].drop_duplicates(subset=['StopUID']).sort_values(['StopUID'])\n",
    "\n",
    "    df_final, report_text = match_stop_coordinates(\n",
    "        dfstop=df_stop.copy().rename(columns = {'StopName':'StopName_Zh'}),\n",
    "        stop_gdf=df_stopfromseq,\n",
    "        col_uid=\"StopUID\",\n",
    "        col_name=\"StopName_Zh\",\n",
    "        col_lat=\"PositionLat\",\n",
    "        col_lon=\"PositionLon\"\n",
    "    )\n",
    "\n",
    "    print(report_text)\n",
    "\n",
    "\n",
    "\n",
    "    # a = df_final[((df_final['PositionLon'].isna()) | (df_final['PositionLat'].isna())) & (df_final['StopUID'] != \"-99\")][['StopUID', 'StopName_Zh']].drop_duplicates()\n",
    "    # a['Auth'] = a['StopUID'].str[:3]\n",
    "    # a.sort_values(['Auth'])\n",
    "\n",
    "# pre03_findstops(checkok_ticketfolder, seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daecf5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理04: 加上必要欄位 (平假日欄位、刪除不重要的欄位）\n",
    "\n",
    "def add_weekdayandweekendcolumns(df, \n",
    "                                 timecolumns='InfoDate',\n",
    "                                 filterdate=None):\n",
    "    \"\"\"\n",
    "    將 DataFrame 中的時間欄位轉換為日期時間格式，新增 DaysofWeek 和 WDWK 欄位，\n",
    "    並可選擇性地過濾掉特定日期。\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 原始 DataFrame。\n",
    "        timecolumns (str): 包含日期的欄位名稱，預設為 'InfoDate'。\n",
    "        filterdate (list/None): 要過濾掉的日期字串列表 (例如 ['YYYY-MM-DD'])。\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 處理後的 DataFrame。\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. 將時間欄位轉換為 datetime\n",
    "    df[timecolumns] = pd.to_datetime(df[timecolumns], errors='coerce')\n",
    "\n",
    "    # 2. 新增 'DaysofWeek' 欄位\n",
    "    \n",
    "    df['DaysofWeek'] = df[timecolumns].dt.dayofweek # .dt.dayofweek 會回傳：0=週一, 1=週二, ..., 6=週日\n",
    "\n",
    "    # 3. 處理過濾日期 (如果 filterdate 不是 None 且有內容)\n",
    "    if filterdate and len(filterdate) > 0:\n",
    "        # 將 filterdate 列表轉換為 datetime 格式，以便進行比較\n",
    "        filter_dates_dt = pd.to_datetime(filterdate)\n",
    "        \n",
    "        # 找出不在 filter_dates_dt 中的日期 (布林遮罩)\n",
    "        # .dt.normalize() 將日期時間的時間部分設為 00:00:00，確保只比較日期\n",
    "        filter_mask = ~df[timecolumns].dt.normalize().isin(filter_dates_dt)\n",
    "        \n",
    "        # 套用遮罩，只保留不在過濾列表中的資料\n",
    "        df = df[filter_mask].copy()\n",
    "\n",
    "    # 4. 新增 'WDWK' 欄位\n",
    "    # .dt.dayofweek 回傳：0=週一, 1=週二, 2=週三, 3=週四, 4=週五, 5=週六, 6=週日\n",
    "    \n",
    "    # 定義條件：\n",
    "    # WDWK = 1 (週二=1, 週三=2, 週四=3)\n",
    "    wdwk_1_condition = df['DaysofWeek'].isin([1, 2, 3])\n",
    "    \n",
    "    # WDWK = -1 (週六=5, 週日=6)\n",
    "    wdwk_neg1_condition = df['DaysofWeek'].isin([5, 6])\n",
    "    \n",
    "    # 使用 np.select (比多個 if/elif 判斷更快)\n",
    "    \n",
    "    df['WDWK'] = np.select(\n",
    "        [wdwk_1_condition, wdwk_neg1_condition], # 條件列表\n",
    "        [1, 0],                                # 對應的值\n",
    "        default=-1                               # 預設值 (其他日子=1)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def must_outputformat(df):\n",
    "    df['BoardingTime'] = pd.to_datetime(df['BoardingTime'], errors='coerce')\n",
    "    df['DeboardingTime'] = pd.to_datetime(df['DeboardingTime'], errors='coerce')\n",
    "    df['BoardinngDate'] = df['BoardingTime'].dt.date\n",
    "    df['DeboardingDate'] = df['DeboardingTime'].dt.date\n",
    "    df['BoardingHour'] = df['BoardingTime'].dt.hour\n",
    "    df['DeboardingHour'] = df['DeboardingTime'].dt.hour\n",
    "\n",
    "    reindexcolumns = ['Authority', 'OperatorNo', 'HolderType', 'TicketType', 'SubTicketType', \n",
    "                    'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', 'Direction', \n",
    "                    'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence', 'BoardinngDate',  'BoardingHour', \n",
    "                    'DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence', 'DeboardingDate', 'DeboardingHour',\n",
    "                    'InfoDate', 'DaysofWeek', 'WDWK']\n",
    "\n",
    "    df = df.reindex(columns=reindexcolumns)\n",
    "    return df \n",
    "\n",
    "def pre04_reformat(checkok_ticketfolder, reformat_folder, filterdate = None):\n",
    "\n",
    "    filelist = findfiles(checkok_ticketfolder, filetype='csv', recursive=False)\n",
    "\n",
    "    for file in filelist:\n",
    "\n",
    "        reformat_output_file = os.path.join(\n",
    "            reformat_folder,\n",
    "            os.path.basename(file).replace(\"_cleaned.csv\", \"_reformatted.csv\")\n",
    "        )\n",
    "\n",
    "\n",
    "        # 如果 mark_ticket_errors 需要全表上下文，改成 chunksize=None\n",
    "        reader = pd.read_csv(file, chunksize=1000)\n",
    "\n",
    "        first_chunk = True\n",
    "        for chunk in reader:\n",
    "\n",
    "            output = add_weekdayandweekendcolumns(df=chunk,\n",
    "                                            timecolumns= 'InfoDate', \n",
    "                                            filterdate = filterdate)\n",
    "            output = must_outputformat(output)\n",
    "\n",
    "            output.to_csv(\n",
    "                reformat_output_file,\n",
    "                mode='w' if first_chunk else 'a',\n",
    "                header=first_chunk,\n",
    "                index=False,\n",
    "                encoding='utf-8-sig'\n",
    "            )\n",
    "            first_chunk = False  \n",
    "\n",
    "# pre04_reformat(checkok_ticketfolder, reformat_folder, filterdate = ['2024-10-09', '2024-10-10', '2024-10-11', '2024-10-12', '2024-10-13', '2024-10-14', '2024-10-15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da6279df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析01: 確認資料各票種、各路線、平假日、起點、迄點筆數\n",
    "def analytics01_hourlycount(reformat_folder, \n",
    "                            hourlycount_folder, \n",
    "                            seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\",\n",
    "                            returndf = True):\n",
    "\n",
    "    files = findfiles(reformat_folder)\n",
    "    files = [f for f in files if 'TO1' in f]\n",
    "    df = read_combined_dataframe(files)\n",
    "\n",
    "    groupbycolumns = ['InfoDate', 'DaysofWeek', 'WDWK','Authority', 'HolderType', \n",
    "                      'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', 'Direction',\n",
    "                      'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence', 'BoardinngDate', 'BoardingHour',\n",
    "                      'DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence', 'DeboardingDate', 'DeboardingHour', 'FilePath']\n",
    "\n",
    "    df[groupbycolumns] = df[groupbycolumns].fillna('-99')\n",
    "    df_count = df.groupby(groupbycolumns).size().reset_index(name='Count')\n",
    "\n",
    "    df_seq = read_combined_dataframe(findfiles(seqfolder, \n",
    "                                            filetype='csv', \n",
    "                                            recursive=False), filepath=False)\n",
    "    df_stopfromseq = df_seq[['StopUID', 'StopName_Zh', 'PositionLon', 'PositionLat']].drop_duplicates(subset=['StopUID']).sort_values(['StopUID'])\n",
    "\n",
    "    df_count = pd.merge(df_count, \n",
    "                        df_stopfromseq[['StopUID', 'PositionLon', 'PositionLat']].rename(columns = {'StopUID':'BoardingStopUID', 'PositionLon':'BoardingLon', 'PositionLat':'BoardingLat'}), \n",
    "                        on = 'BoardingStopUID', \n",
    "                        how='left')\n",
    "\n",
    "    df_count = pd.merge(df_count, \n",
    "                        df_stopfromseq[['StopUID', 'PositionLon', 'PositionLat']].rename(columns = {'StopUID':'DeboardingStopUID', 'PositionLon':'DeboardingLon', 'PositionLat':'DeboardingLat'}), \n",
    "                        on = 'DeboardingStopUID', \n",
    "                        how='left')\n",
    "    df_count = df_count.reindex(columns= ['InfoDate', 'DaysofWeek', 'WDWK', 'HolderType', 'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', 'Direction',\n",
    "                                        'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence','BoardinngDate', 'BoardingHour', 'BoardingLon', 'BoardingLat', \n",
    "                                        'DeboardingStopUID','DeboardingStopName', 'DeboardingStopSequence', 'DeboardingDate', 'DeboardingHour', 'DeboardingLon', 'DeboardingLat', \n",
    "                                        'FilePath', 'Count'])\n",
    "\n",
    "    outputfile = os.path.join(hourlycount_folder, '上下車區分票種分時計次(未修正站序是否正確).csv')\n",
    "    df_count.to_csv(outputfile, index=False)\n",
    "\n",
    "    if returndf:\n",
    "        return df_count\n",
    "\n",
    "# analytics01_hourlycount(reformat_folder, \n",
    "                        # hourlycount_folder, \n",
    "                        # seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\", \n",
    "                        # returndf=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab65d8e2",
   "metadata": {},
   "source": [
    "# Unsured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90489bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理05: 重新比對站序\n",
    "def checkseq(df, df_seq, process_step = 2):\n",
    "\n",
    "    df = df.copy()\n",
    "    df_seq = df_seq.copy()\n",
    "\n",
    "    df = df[~((df['BoardingStopUID'] == \"-99\") | (df['DeboardingStopUID'] == \"-99\"))]\n",
    "\n",
    "    df_seq = df_seq.reindex(columns = ['RouteUID', 'SubRouteUID', 'Direction', 'StopUID', 'StopName_Zh', 'StopSequence']).rename(columns = {'StopName_Zh':'StopName'})\n",
    "\n",
    "    df = pd.merge(df, \n",
    "                df_seq.rename(columns = {'StopUID':'BoardingStopUID',\n",
    "                                        'StopName':'BoardingStopName_S', \n",
    "                                        'StopSequence':'BoardingStopSequence_S'}).drop_duplicates(subset = ['RouteUID', 'SubRouteUID', 'Direction', 'BoardingStopUID']),\n",
    "                on = ['RouteUID', 'SubRouteUID', 'Direction', 'BoardingStopUID'],\n",
    "                how = 'left')\n",
    "\n",
    "    df = pd.merge(df, \n",
    "                df_seq.rename(columns = {'StopUID':'DeboardingStopUID',\n",
    "                                        'StopName':'DeboardingStopName_S', \n",
    "                                        'StopSequence':'DeboardingStopSequence_S'}).drop_duplicates(subset = ['RouteUID', 'SubRouteUID', 'Direction', 'DeboardingStopUID']),\n",
    "                on = ['RouteUID', 'SubRouteUID', 'Direction', 'DeboardingStopUID'],\n",
    "                how = 'left')\n",
    "\n",
    "    df_keep = df[(df['BoardingStopSequence'] == df['BoardingStopSequence_S']) & \n",
    "                (df['DeboardingStopSequence'] == df['DeboardingStopSequence_S'])].drop(columns = ['BoardingStopName_S', 'BoardingStopSequence_S', 'DeboardingStopName_S', 'DeboardingStopSequence_S'])\n",
    "\n",
    "    df_process = df[(df['BoardingStopSequence'] != df['BoardingStopSequence_S']) |\n",
    "                    (df['DeboardingStopSequence'] != df['DeboardingStopSequence_S'])]\n",
    "\n",
    "    \n",
    "    \n",
    "    if process_step == 2:\n",
    "\n",
    "        # 轉成數值，轉換失敗為 NaN\n",
    "        df_process['BoardingStopSequence_S'] = pd.to_numeric(df_process['BoardingStopSequence_S'], errors='coerce')\n",
    "        df_process['DeboardingStopSequence_S'] = pd.to_numeric(df_process['DeboardingStopSequence_S'], errors='coerce')\n",
    "\n",
    "        # 建立布林遮罩\n",
    "        mask = df_process['BoardingStopSequence_S'] < df_process['DeboardingStopSequence_S']\n",
    "        mask = mask.fillna(False)   # 避免 NaN 導致問題（可選）\n",
    "\n",
    "        # 依條件寫入主欄位\n",
    "        df_process.loc[mask, 'BoardingStopSequence']  = df_process.loc[mask, 'BoardingStopSequence_S']\n",
    "        df_process.loc[mask, 'DeboardingStopSequence'] = df_process.loc[mask, 'DeboardingStopSequence_S']\n",
    "\n",
    "        # 要刪掉的暫存欄位\n",
    "        cols_to_drop = ['BoardingStopName_S', 'BoardingStopSequence_S',\n",
    "                        'DeboardingStopName_S', 'DeboardingStopSequence_S']\n",
    "\n",
    "        # concat 前先 drop\n",
    "        df_keep = pd.concat([\n",
    "            df_keep,\n",
    "            df_process.loc[mask].drop(columns=cols_to_drop, errors='ignore')\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        # 剩下的資料繼續處理\n",
    "        df_process = df_process.loc[~mask].copy()\n",
    "    \n",
    "    return df_keep, df_process\n",
    "\n",
    "def matchwithstopname(df, df_seq, df_done):\n",
    "    df_seq = df_seq.copy()\n",
    "    df = df.copy()\n",
    "    reindexcolumns = df.columns.tolist()\n",
    "    donecolumns = df_done.head().columns.tolist()\n",
    "    df_seq = df_seq.reindex(columns = ['RouteUID', 'SubRouteUID', 'Direction', 'StopUID', 'StopName_Zh', 'StopSequence']).rename(columns = {'StopName_Zh':'StopName'})\n",
    "\n",
    "\n",
    "    # 一、用RouteUID、SubRouteUID、StopName的組合再比對一次站序及站點編號 (因比對不到的)\n",
    "    # 1. 比對起點站名\n",
    "    mask_boardingseq = df['BoardingStopSequence_S'].isna()\n",
    "    df_temp = df[mask_boardingseq].copy()\n",
    "    df_temp = df_temp.drop(columns = ['BoardingStopName_S', 'BoardingStopSequence_S'])\n",
    "\n",
    "    df_temp = pd.merge(df_temp, \n",
    "                    df_seq.rename(columns = {'StopUID':'BoardingStopUID_S',\n",
    "                                                'StopName':'BoardingStopName', \n",
    "                                                'StopSequence':'BoardingStopSequence_S'}).drop_duplicates(subset = ['RouteUID', 'SubRouteUID', 'Direction', 'BoardingStopName']),\n",
    "                    on = ['RouteUID', 'SubRouteUID', 'Direction', 'BoardingStopName'],\n",
    "                    how = 'left')\n",
    "\n",
    "    mask_boardingstopuid = df_temp['BoardingStopSequence_S'].notna()\n",
    "    df_temp.loc[mask_boardingstopuid, 'BoardingStopSequence'] = df_temp.loc[mask_boardingstopuid, 'BoardingStopSequence_S']\n",
    "    df_temp.loc[mask_boardingstopuid, 'BoardingStopUID'] = df_temp.loc[mask_boardingstopuid, 'BoardingStopUID_S']\n",
    "    df = pd.concat([df[~mask_boardingseq], \n",
    "                    df_temp]).sort_index()\n",
    "\n",
    "    df = df.reindex(columns=reindexcolumns)\n",
    "\n",
    "    # 2. 比對起點站名\n",
    "    mask_deboardingseq = df['DeboardingStopSequence_S'].isna()\n",
    "    df_temp = df[mask_deboardingseq].copy()\n",
    "    df_temp = df_temp.drop(columns = ['DeboardingStopName_S', 'DeboardingStopSequence_S'])\n",
    "\n",
    "    df_temp = pd.merge(df_temp, \n",
    "                    df_seq.rename(columns = {'StopUID':'DeboardingStopUID_S',\n",
    "                                                'StopName':'DeboardingStopName', \n",
    "                                                'StopSequence':'DeboardingStopSequence_S'}).drop_duplicates(subset = ['RouteUID', 'SubRouteUID', 'Direction', 'DeboardingStopName']),\n",
    "                    on = ['RouteUID', 'SubRouteUID', 'Direction', 'DeboardingStopName'],\n",
    "                    how = 'left')\n",
    "\n",
    "    mask_deboardingstopuid = df_temp['DeboardingStopSequence_S'].notna()\n",
    "    df_temp.loc[mask_deboardingstopuid, 'DeboardingStopSequence'] = df_temp.loc[mask_deboardingstopuid, 'DeboardingStopSequence_S']\n",
    "    df_temp.loc[mask_deboardingstopuid, 'DeboardingStopUID'] = df_temp.loc[mask_deboardingstopuid, 'DeboardingStopUID_S']\n",
    "    df = pd.concat([df[~mask_deboardingseq], \n",
    "                    df_temp]).sort_index()\n",
    "\n",
    "    df = df.reindex(columns=reindexcolumns)\n",
    "\n",
    "    # 二、更新他們的StopSequence\n",
    "    mask = (df['BoardingStopSequence_S'] < df['DeboardingStopSequence_S'])\n",
    "    df.loc[mask, 'BoardingStopSequence'] = df.loc[mask, 'BoardingStopSequence_S']\n",
    "    df.loc[mask, 'DeboardingStopSequence'] = df.loc[mask, 'DeboardingStopSequence_S']\n",
    "\n",
    "    df_done = pd.concat([df_done, \n",
    "                         df[mask]])\n",
    "    df_done = df_done.reindex(columns = donecolumns)\n",
    "    \n",
    "    \n",
    "\n",
    "    return df_done, df[~mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchwith_anotherdirection(df, df_seq, df_done):\n",
    "\n",
    "    # 轉方向再計算一次\n",
    "    done_columns = df_done.columns.tolist()\n",
    "    \n",
    "    df_seq = df_seq.reindex(columns = ['RouteUID', 'SubRouteUID', 'Direction', 'StopUID', 'StopName_Zh', 'StopSequence']).rename(columns = {'StopName_Zh':'StopName'})\n",
    "\n",
    "    mask = df['BoardingStopSequence_S'] > df['DeboardingStopSequence_S']\n",
    "    df_temp = df[mask]\n",
    "\n",
    "    df_temp['Direction_another'] = 1 - df_temp['Direction']\n",
    "    df_temp = pd.merge(df_temp, \n",
    "                    df_seq.rename(columns = {'StopUID':'BoardingStopUID',\n",
    "                                                'StopName':'BoardingStopName_S2', \n",
    "                                                'StopSequence':'BoardingStopSequence_S2',\n",
    "                                                'Direction':'Direction_another'}).drop_duplicates(subset = ['RouteUID', 'SubRouteUID', 'Direction_another', 'BoardingStopUID']),\n",
    "                        on = ['RouteUID', 'SubRouteUID', 'Direction_another', 'BoardingStopUID'],\n",
    "                        how = 'left')\n",
    "\n",
    "    df_temp = pd.merge(df_temp, \n",
    "                    df_seq.rename(columns = {'StopUID':'DeboardingStopUID',\n",
    "                                                'StopName':'DeboardingStopName_S2', \n",
    "                                                'StopSequence':'DeboardingStopSequence_S2',\n",
    "                                                'Direction':'Direction_another'}).drop_duplicates(subset = ['RouteUID', 'SubRouteUID', 'Direction_another', 'DeboardingStopUID']),\n",
    "                        on = ['RouteUID', 'SubRouteUID', 'Direction_another', 'DeboardingStopUID'],\n",
    "                        how = 'left')\n",
    "\n",
    "    mask_anotherdirection = df_temp['BoardingStopSequence_S2'] < df_temp['DeboardingStopSequence_S2']\n",
    "    df_temp.loc[mask_anotherdirection, 'Direction'] = df_temp.loc[mask_anotherdirection, 'Direction_another']\n",
    "    df_temp.loc[mask_anotherdirection, 'BoardingStopSequence'] = df_temp.loc[mask_anotherdirection, 'BoardingStopSequence_S2']\n",
    "    df_temp.loc[mask_anotherdirection, 'DeboardingStopSequence'] = df_temp.loc[mask_anotherdirection, 'DeboardingStopSequence_S2']\n",
    "    df_done = pd.concat([df_done, \n",
    "                        df_temp[mask_anotherdirection].reindex(columns = done_columns)])\n",
    "\n",
    "    df_temp = df_temp[~mask_anotherdirection]\n",
    "\n",
    "    mask_turnaround = ((df_temp['BoardingStopSequence_S2'].notna()) & (df_temp['DeboardingStopSequence_S2'].isna())) & (df_temp['BoardingStopSequence_S2'] < df_temp['DeboardingStopSequence_S'])\n",
    "    df_temp.loc[mask_turnaround, 'BoardingStopSequence'] = df_temp.loc[mask_turnaround, 'BoardingStopSequence_S2']\n",
    "    df_temp.loc[mask_turnaround, 'DeboardingStopSequence'] = df_temp.loc[mask_turnaround, 'DeboardingStopSequence_S']\n",
    "    df_temp.loc[mask_turnaround, 'Direction'] = df_temp.loc[mask_turnaround, 'Direction_another']\n",
    "    df_done = pd.concat([df_done, \n",
    "                        df_temp[mask_turnaround].reindex(columns = done_columns)])\n",
    "\n",
    "    df_temp = df_temp[~mask_turnaround]\n",
    "    df_temp = pd.concat([df[~mask], \n",
    "                         df_temp])\n",
    "\n",
    "    return df_done, df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97835db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kjchang\\AppData\\Local\\Temp\\ipykernel_20528\\3023297734.py:2: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\02_初步分析\\01_分時計次\\上下車區分票種分時計次(未修正站序是否正確).csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24650330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kjchang\\AppData\\Local\\Temp\\ipykernel_20528\\13492506.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_process['BoardingStopSequence_S'] = pd.to_numeric(df_process['BoardingStopSequence_S'], errors='coerce')\n",
      "C:\\Users\\kjchang\\AppData\\Local\\Temp\\ipykernel_20528\\13492506.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_process['DeboardingStopSequence_S'] = pd.to_numeric(df_process['DeboardingStopSequence_S'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次處理:透過StopUID比對\n",
      "21745652 2823202 24568854\n",
      "第2次處理:透過StopName比對\n",
      "22870311 1698543 24568854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kjchang\\AppData\\Local\\Temp\\ipykernel_20528\\808088466.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Direction_another'] = 1 - df_temp['Direction']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3次處理：轉方向處理\n",
      "22917073 1651781 24568854\n"
     ]
    }
   ],
   "source": [
    "# 讀取預處理資料 \n",
    "df = pd.read_csv(r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\02_初步分析\\01_分時計次\\上下車區分票種分時計次(未修正站序是否正確).csv\")\n",
    "print(len(df))\n",
    "\n",
    "seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\"\n",
    "df_seq = read_combined_dataframe(file_list=findfiles(seqfolder))\n",
    "df_seq = df_seq.reindex(columns = ['RouteUID', 'RouteName_Zh', 'SubRouteUID', 'SubRouteName_Zh', 'Direction', 'StopUID', 'StopName_Zh', 'StopSequence', 'PositionLon', 'PositionLat'])\n",
    "\n",
    "df_done, df_temp = checkseq(df, df_seq) # 根據RouteUID、SubRouteUID、Direction、StopUID 比對出新的站序\n",
    "print(\"第1次處理:透過StopUID比對\")\n",
    "print(len(df_done), len(df_temp), len(df_done) + len(df_temp))\n",
    "\n",
    "df_done, df_temp = matchwithstopname(df = df_temp, df_seq = df_seq, df_done = df_done) # 根據RouteUID、SubRouteUID、Direction、StopName 比對出新的站序\n",
    "print(\"第2次處理:透過StopName比對\")\n",
    "print(len(df_done), len(df_temp), len(df_done) + len(df_temp))\n",
    "\n",
    "df_done, df_temp = matchwith_anotherdirection(df = df_temp, df_seq = df_seq, df_done = df_done) # 比較另外一個方向的站序，如果是通往底站折返的站點轉換為另外一個方向的站點資訊\n",
    "print(\"第3次處理：轉方向處理\")\n",
    "print(len(df_done), len(df_temp), len(df_done) + len(df_temp))\n",
    "\n",
    "df = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5902978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InfoDate</th>\n",
       "      <th>DaysofWeek</th>\n",
       "      <th>WDWK</th>\n",
       "      <th>HolderType</th>\n",
       "      <th>RouteUID</th>\n",
       "      <th>RouteName</th>\n",
       "      <th>SubRouteUID</th>\n",
       "      <th>SubRouteName</th>\n",
       "      <th>Direction</th>\n",
       "      <th>BoardingStopUID</th>\n",
       "      <th>...</th>\n",
       "      <th>Count</th>\n",
       "      <th>BoardingStopName_S</th>\n",
       "      <th>BoardingStopSequence_S</th>\n",
       "      <th>DeboardingStopName_S</th>\n",
       "      <th>DeboardingStopSequence_S</th>\n",
       "      <th>Direction_another</th>\n",
       "      <th>BoardingStopName_S2</th>\n",
       "      <th>BoardingStopSequence_S2</th>\n",
       "      <th>DeboardingStopName_S2</th>\n",
       "      <th>DeboardingStopSequence_S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NWT10151</td>\n",
       "      <td>701</td>\n",
       "      <td>NWT101510</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT34197</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>祖師廟(康定)</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NWT10151</td>\n",
       "      <td>701</td>\n",
       "      <td>NWT101510</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT34197</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>西門國小(臺大醫院北護分院)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NWT10151</td>\n",
       "      <td>701</td>\n",
       "      <td>NWT101510</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT34197</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>祖師廟(康定)</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NWT10151</td>\n",
       "      <td>701</td>\n",
       "      <td>NWT101510</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT34197</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>峨眉街口(中醫院區)</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NWT10151</td>\n",
       "      <td>701</td>\n",
       "      <td>NWT101510</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT34197</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>西門國小(臺大醫院北護分院)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634346</th>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>C09</td>\n",
       "      <td>TAO5109</td>\n",
       "      <td>5109</td>\n",
       "      <td>TAO5109</td>\n",
       "      <td>5109</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO62273</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>長興</td>\n",
       "      <td>63.0</td>\n",
       "      <td>大溪總站</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>大溪總站</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634347</th>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>C09</td>\n",
       "      <td>TAO5109</td>\n",
       "      <td>5109</td>\n",
       "      <td>TAO5109</td>\n",
       "      <td>5109</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO62277</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>奎輝</td>\n",
       "      <td>59.0</td>\n",
       "      <td>大溪總站</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>大溪總站</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634348</th>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>C09</td>\n",
       "      <td>TAO5109</td>\n",
       "      <td>5109</td>\n",
       "      <td>TAO5109</td>\n",
       "      <td>5109</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO62280</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>優點頂</td>\n",
       "      <td>55.0</td>\n",
       "      <td>大溪總站</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>大溪總站</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634349</th>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>C09</td>\n",
       "      <td>TAO602</td>\n",
       "      <td>BR</td>\n",
       "      <td>TAO602</td>\n",
       "      <td>BR</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO39053</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>丹鳳國小(新北大道)</td>\n",
       "      <td>34.0</td>\n",
       "      <td>囍家社區</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634351</th>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>C09</td>\n",
       "      <td>TAO9060</td>\n",
       "      <td>F906</td>\n",
       "      <td>TAO9060</td>\n",
       "      <td>F906</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO2903</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>東眼山國家森林遊樂區(下客站)</td>\n",
       "      <td>38.0</td>\n",
       "      <td>綠光森林</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>綠光森林</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1651781 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          InfoDate  DaysofWeek  WDWK HolderType  RouteUID RouteName  \\\n",
       "0       2024-10-01           1     1          A  NWT10151       701   \n",
       "1       2024-10-01           1     1          A  NWT10151       701   \n",
       "2       2024-10-01           1     1          A  NWT10151       701   \n",
       "3       2024-10-01           1     1          A  NWT10151       701   \n",
       "4       2024-10-01           1     1          A  NWT10151       701   \n",
       "...            ...         ...   ...        ...       ...       ...   \n",
       "634346  2024-11-30           5     0        C09   TAO5109      5109   \n",
       "634347  2024-11-30           5     0        C09   TAO5109      5109   \n",
       "634348  2024-11-30           5     0        C09   TAO5109      5109   \n",
       "634349  2024-11-30           5     0        C09    TAO602        BR   \n",
       "634351  2024-11-30           5     0        C09   TAO9060      F906   \n",
       "\n",
       "       SubRouteUID SubRouteName  Direction BoardingStopUID  ... Count  \\\n",
       "0        NWT101510          701          0        NWT34197  ...     1   \n",
       "1        NWT101510          701          0        NWT34197  ...     1   \n",
       "2        NWT101510          701          0        NWT34197  ...     2   \n",
       "3        NWT101510          701          0        NWT34197  ...     1   \n",
       "4        NWT101510          701          0        NWT34197  ...     3   \n",
       "...            ...          ...        ...             ...  ...   ...   \n",
       "634346     TAO5109         5109          0        TAO62273  ...     2   \n",
       "634347     TAO5109         5109          0        TAO62277  ...     1   \n",
       "634348     TAO5109         5109          0        TAO62280  ...     1   \n",
       "634349      TAO602           BR          0        TAO39053  ...     1   \n",
       "634351     TAO9060         F906          0         TAO2903  ...     1   \n",
       "\n",
       "        BoardingStopName_S BoardingStopSequence_S  DeboardingStopName_S  \\\n",
       "0                      NaN                    NaN               祖師廟(康定)   \n",
       "1                      NaN                    NaN        西門國小(臺大醫院北護分院)   \n",
       "2                      NaN                    NaN               祖師廟(康定)   \n",
       "3                      NaN                    NaN            峨眉街口(中醫院區)   \n",
       "4                      NaN                    NaN        西門國小(臺大醫院北護分院)   \n",
       "...                    ...                    ...                   ...   \n",
       "634346                  長興                   63.0                  大溪總站   \n",
       "634347                  奎輝                   59.0                  大溪總站   \n",
       "634348                 優點頂                   55.0                  大溪總站   \n",
       "634349          丹鳳國小(新北大道)                   34.0                  囍家社區   \n",
       "634351     東眼山國家森林遊樂區(下客站)                   38.0                  綠光森林   \n",
       "\n",
       "        DeboardingStopSequence_S  Direction_another BoardingStopName_S2  \\\n",
       "0                           59.0                NaN                 NaN   \n",
       "1                           60.0                NaN                 NaN   \n",
       "2                           59.0                NaN                 NaN   \n",
       "3                           61.0                NaN                 NaN   \n",
       "4                           60.0                NaN                 NaN   \n",
       "...                          ...                ...                 ...   \n",
       "634346                       1.0                1.0                 NaN   \n",
       "634347                       1.0                1.0                 NaN   \n",
       "634348                       1.0                1.0                 NaN   \n",
       "634349                      18.0                1.0                 NaN   \n",
       "634351                      35.0                1.0                 NaN   \n",
       "\n",
       "       BoardingStopSequence_S2  DeboardingStopName_S2  \\\n",
       "0                          NaN                    NaN   \n",
       "1                          NaN                    NaN   \n",
       "2                          NaN                    NaN   \n",
       "3                          NaN                    NaN   \n",
       "4                          NaN                    NaN   \n",
       "...                        ...                    ...   \n",
       "634346                     NaN                   大溪總站   \n",
       "634347                     NaN                   大溪總站   \n",
       "634348                     NaN                   大溪總站   \n",
       "634349                     NaN                    NaN   \n",
       "634351                     NaN                   綠光森林   \n",
       "\n",
       "       DeboardingStopSequence_S2  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "...                          ...  \n",
       "634346                      71.0  \n",
       "634347                      71.0  \n",
       "634348                      71.0  \n",
       "634349                       NaN  \n",
       "634351                       4.0  \n",
       "\n",
       "[1651781 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['BoardingStopName', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff057483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubRouteUID</th>\n",
       "      <th>Direction</th>\n",
       "      <th>BoardingStopUID</th>\n",
       "      <th>BoardingStopName</th>\n",
       "      <th>DeboardingStopUID</th>\n",
       "      <th>DeboardingStopName</th>\n",
       "      <th>BoardingStopSequence</th>\n",
       "      <th>BoardingStopSequence_S</th>\n",
       "      <th>BoardingStopSequence_S2</th>\n",
       "      <th>DeboardingStopSequence</th>\n",
       "      <th>DeboardingStopSequence_S</th>\n",
       "      <th>DeboardingStopSequence_S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NWT158438</td>\n",
       "      <td>1</td>\n",
       "      <td>NWT15894</td>\n",
       "      <td>捷運新埔站(文化路)</td>\n",
       "      <td>NWT15894</td>\n",
       "      <td>捷運新埔站(文化路)</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>NWT157418</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT123459</td>\n",
       "      <td>楓子林路口</td>\n",
       "      <td>NWT123459</td>\n",
       "      <td>楓子林路口</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>NWT157418</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT193171</td>\n",
       "      <td>坪林站</td>\n",
       "      <td>NWT193171</td>\n",
       "      <td>坪林站</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>NWT157418</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT193171</td>\n",
       "      <td>坪林站</td>\n",
       "      <td>NWT193171</td>\n",
       "      <td>坪林站</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NWT157419</td>\n",
       "      <td>1</td>\n",
       "      <td>NWT123512</td>\n",
       "      <td>板橋車站(文化路)</td>\n",
       "      <td>NWT123512</td>\n",
       "      <td>板橋車站(文化路)</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823108</th>\n",
       "      <td>TAO6030</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO9404</td>\n",
       "      <td>新北大道壽山路口</td>\n",
       "      <td>TAO9404</td>\n",
       "      <td>新北大道壽山路口</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823750</th>\n",
       "      <td>TAO6030</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO9404</td>\n",
       "      <td>新北大道壽山路口</td>\n",
       "      <td>TAO9404</td>\n",
       "      <td>新北大道壽山路口</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823751</th>\n",
       "      <td>TAO6030</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO9404</td>\n",
       "      <td>新北大道壽山路口</td>\n",
       "      <td>TAO9404</td>\n",
       "      <td>新北大道壽山路口</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824139</th>\n",
       "      <td>TAO3010</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO1044</td>\n",
       "      <td>桃園醫院</td>\n",
       "      <td>TAO1044</td>\n",
       "      <td>桃園醫院</td>\n",
       "      <td>21</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825043</th>\n",
       "      <td>TAO36420</td>\n",
       "      <td>1</td>\n",
       "      <td>TAO12750</td>\n",
       "      <td>蚵間里福興宮</td>\n",
       "      <td>TAO12750</td>\n",
       "      <td>蚵間里福興宮</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4912 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SubRouteUID  Direction BoardingStopUID BoardingStopName  \\\n",
       "11        NWT158438          1        NWT15894       捷運新埔站(文化路)   \n",
       "313       NWT157418          0       NWT123459            楓子林路口   \n",
       "346       NWT157418          0       NWT193171              坪林站   \n",
       "349       NWT157418          0       NWT193171              坪林站   \n",
       "595       NWT157419          1       NWT123512        板橋車站(文化路)   \n",
       "...             ...        ...             ...              ...   \n",
       "1823108     TAO6030          0         TAO9404         新北大道壽山路口   \n",
       "1823750     TAO6030          0         TAO9404         新北大道壽山路口   \n",
       "1823751     TAO6030          0         TAO9404         新北大道壽山路口   \n",
       "1824139     TAO3010          0         TAO1044             桃園醫院   \n",
       "1825043    TAO36420          1        TAO12750           蚵間里福興宮   \n",
       "\n",
       "        DeboardingStopUID DeboardingStopName  BoardingStopSequence  \\\n",
       "11               NWT15894         捷運新埔站(文化路)                    11   \n",
       "313             NWT123459              楓子林路口                     4   \n",
       "346             NWT193171                坪林站                     1   \n",
       "349             NWT193171                坪林站                     1   \n",
       "595             NWT123512          板橋車站(文化路)                     3   \n",
       "...                   ...                ...                   ...   \n",
       "1823108           TAO9404           新北大道壽山路口                    13   \n",
       "1823750           TAO9404           新北大道壽山路口                    13   \n",
       "1823751           TAO9404           新北大道壽山路口                    13   \n",
       "1824139           TAO1044               桃園醫院                    21   \n",
       "1825043          TAO12750             蚵間里福興宮                     1   \n",
       "\n",
       "         BoardingStopSequence_S  BoardingStopSequence_S2  \\\n",
       "11                         11.0                      NaN   \n",
       "313                         4.0                      NaN   \n",
       "346                         1.0                      NaN   \n",
       "349                         1.0                      NaN   \n",
       "595                         3.0                      NaN   \n",
       "...                         ...                      ...   \n",
       "1823108                    13.0                      NaN   \n",
       "1823750                    13.0                      NaN   \n",
       "1823751                    13.0                      NaN   \n",
       "1824139                    21.0                      NaN   \n",
       "1825043                     1.0                      NaN   \n",
       "\n",
       "         DeboardingStopSequence  DeboardingStopSequence_S  \\\n",
       "11                           11                      11.0   \n",
       "313                           4                       4.0   \n",
       "346                           1                       1.0   \n",
       "349                           1                       1.0   \n",
       "595                           3                       3.0   \n",
       "...                         ...                       ...   \n",
       "1823108                      13                      13.0   \n",
       "1823750                      13                      13.0   \n",
       "1823751                      13                      13.0   \n",
       "1824139                      21                      21.0   \n",
       "1825043                       1                       1.0   \n",
       "\n",
       "         DeboardingStopSequence_S2  \n",
       "11                             NaN  \n",
       "313                            NaN  \n",
       "346                            NaN  \n",
       "349                            NaN  \n",
       "595                            NaN  \n",
       "...                            ...  \n",
       "1823108                        NaN  \n",
       "1823750                        NaN  \n",
       "1823751                        NaN  \n",
       "1824139                        NaN  \n",
       "1825043                        NaN  \n",
       "\n",
       "[4912 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_samestop = df['BoardingStopUID'] == df['DeboardingStopUID']\n",
    "mask = (df['BoardingStopSequence'].notna()) & (df['DeboardingStopSequence'].notna())  & (df['BoardingStopSequence_S'].notna())  & (df['DeboardingStopSequence_S'].notna())& (df['BoardingStopSequence'] < df['DeboardingStopSequence'])\n",
    "df[mask_samestop].reindex(columns = ['SubRouteUID','Direction','BoardingStopUID', 'BoardingStopName', 'DeboardingStopUID', 'DeboardingStopName', 'BoardingStopSequence', 'BoardingStopSequence_S', 'BoardingStopSequence_S2', 'DeboardingStopSequence', 'DeboardingStopSequence_S', 'DeboardingStopSequence_S2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "305f9762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RouteUID</th>\n",
       "      <th>RouteName_Zh</th>\n",
       "      <th>SubRouteUID</th>\n",
       "      <th>SubRouteName_Zh</th>\n",
       "      <th>Direction</th>\n",
       "      <th>StopUID</th>\n",
       "      <th>StopName_Zh</th>\n",
       "      <th>StopSequence</th>\n",
       "      <th>PositionLon</th>\n",
       "      <th>PositionLat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122036</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO6465</td>\n",
       "      <td>中壢總站</td>\n",
       "      <td>1</td>\n",
       "      <td>121.223906</td>\n",
       "      <td>24.953018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122037</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO4157</td>\n",
       "      <td>第一銀行</td>\n",
       "      <td>2</td>\n",
       "      <td>121.222028</td>\n",
       "      <td>24.955308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122038</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO64908</td>\n",
       "      <td>第一市場</td>\n",
       "      <td>3</td>\n",
       "      <td>121.220106</td>\n",
       "      <td>24.955536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122039</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO64243</td>\n",
       "      <td>舊社</td>\n",
       "      <td>4</td>\n",
       "      <td>121.216409</td>\n",
       "      <td>24.955597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122040</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO64126</td>\n",
       "      <td>新明國中(民族路)</td>\n",
       "      <td>5</td>\n",
       "      <td>121.212782</td>\n",
       "      <td>24.956189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122194</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO64130</td>\n",
       "      <td>新明路口</td>\n",
       "      <td>159</td>\n",
       "      <td>121.213670</td>\n",
       "      <td>24.956904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122195</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO64044</td>\n",
       "      <td>舊社</td>\n",
       "      <td>160</td>\n",
       "      <td>121.216306</td>\n",
       "      <td>24.955412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122196</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO63844</td>\n",
       "      <td>河川教育中心</td>\n",
       "      <td>161</td>\n",
       "      <td>121.219178</td>\n",
       "      <td>24.954974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122197</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO64880</td>\n",
       "      <td>第一銀行</td>\n",
       "      <td>162</td>\n",
       "      <td>121.221976</td>\n",
       "      <td>24.955072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122198</th>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>TAO5039</td>\n",
       "      <td>5039</td>\n",
       "      <td>0</td>\n",
       "      <td>TAO64910</td>\n",
       "      <td>中壢總站</td>\n",
       "      <td>163</td>\n",
       "      <td>121.223906</td>\n",
       "      <td>24.953018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RouteUID RouteName_Zh SubRouteUID SubRouteName_Zh  Direction   StopUID  \\\n",
       "122036  TAO5039         5039     TAO5039            5039          0   TAO6465   \n",
       "122037  TAO5039         5039     TAO5039            5039          0   TAO4157   \n",
       "122038  TAO5039         5039     TAO5039            5039          0  TAO64908   \n",
       "122039  TAO5039         5039     TAO5039            5039          0  TAO64243   \n",
       "122040  TAO5039         5039     TAO5039            5039          0  TAO64126   \n",
       "...         ...          ...         ...             ...        ...       ...   \n",
       "122194  TAO5039         5039     TAO5039            5039          0  TAO64130   \n",
       "122195  TAO5039         5039     TAO5039            5039          0  TAO64044   \n",
       "122196  TAO5039         5039     TAO5039            5039          0  TAO63844   \n",
       "122197  TAO5039         5039     TAO5039            5039          0  TAO64880   \n",
       "122198  TAO5039         5039     TAO5039            5039          0  TAO64910   \n",
       "\n",
       "       StopName_Zh  StopSequence  PositionLon  PositionLat  \n",
       "122036        中壢總站             1   121.223906    24.953018  \n",
       "122037        第一銀行             2   121.222028    24.955308  \n",
       "122038        第一市場             3   121.220106    24.955536  \n",
       "122039          舊社             4   121.216409    24.955597  \n",
       "122040   新明國中(民族路)             5   121.212782    24.956189  \n",
       "...            ...           ...          ...          ...  \n",
       "122194        新明路口           159   121.213670    24.956904  \n",
       "122195          舊社           160   121.216306    24.955412  \n",
       "122196      河川教育中心           161   121.219178    24.954974  \n",
       "122197        第一銀行           162   121.221976    24.955072  \n",
       "122198        中壢總站           163   121.223906    24.953018  \n",
       "\n",
       "[163 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq[(df_seq['SubRouteUID'] == 'TAO5039') \n",
    "       & (df_seq['Direction'] == 0)\n",
    "       # & (df_seq['StopSequence'] > 149) & (df_seq['StopSequence'] <= 200)\n",
    "       # & ()\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069452f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_temp))\n",
    "print(df_temp['Count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3501ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['BoardingStopSequence_S'].isna()].reindex(columns = ['RouteUID', 'SubRouteUID', 'Direction', 'Direction_another', \n",
    "                                                                                  'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence', 'BoardingStopName_S', 'BoardingStopSequence_S',\n",
    "                                                                                  'DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence', \n",
    "                                                                                  'DeboardingStopName_S', 'DeboardingStopSequence_S']).drop_duplicates(subset=['SubRouteUID', 'BoardingStopUID','BoardingStopName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f706b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq = df_seq.copy()\n",
    "df_seq = df_seq.reindex(columns = ['RouteUID', 'SubRouteUID', 'Direction', 'StopUID', 'StopName_Zh', 'StopSequence']).rename(columns = {'StopName_Zh':'StopName'})\n",
    "\n",
    "mask_deboardingseq = df['DeboardingStopSequence_S'].isna()\n",
    "\n",
    "df_temp = df[mask_deboardingseq].copy()\n",
    "df_temp['Direction_another'] = 1 - df_temp['Direction']\n",
    "df_temp = df_temp.drop(columns = ['DeboardingStopName_S', 'DeboardingStopSequence_S'])\n",
    "df_temp = pd.merge(df_temp, \n",
    "                   df_seq.rename(columns = {'StopUID':'DeboardingStopUID',\n",
    "                                            'StopName':'DeboardingStopName_S', \n",
    "                                            'StopSequence':'DeboardingStopSequence_S',\n",
    "                                            'Direction':'Direction_another'}).drop_duplicates(subset = ['RouteUID', 'SubRouteUID', 'Direction_another', 'DeboardingStopUID']),\n",
    "                    on = ['RouteUID', 'SubRouteUID', 'Direction_another', 'DeboardingStopUID'],\n",
    "                    how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2345967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.reindex(columns = ['RouteUID', 'SubRouteUID', 'Direction', 'Direction_another', \n",
    "                                                                                  'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence', 'BoardingStopName_S', 'BoardingStopSequence_S',\n",
    "                                                                                  'DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence', \n",
    "                                                                                  'DeboardingStopName_S', 'DeboardingStopSequence_S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409322a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d10816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['BoardingStopSequence'] >= df['DeboardingStopSequence']].reindex(columns = ['RouteUID', 'SubRouteUID', 'Direction', 'Direction_another', \n",
    "                                                                                  'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence', 'BoardingStopName_S', 'BoardingStopSequence_S',\n",
    "                                                                                  'DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence', \n",
    "                                                                                  'DeboardingStopName_S', 'DeboardingStopSequence_S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq[\n",
    "       (df_seq['SubRouteUID'] == 'NWT158438') &\n",
    "       (df_seq['StopName'].str.contains('清水'))\n",
    "       # df_seq['StopUID'] == 'NWT15928'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ea2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\02_初步分析\\01_分時計次\\上下車區分票種分時計次.csv\", nrows = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279989ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析02: 重新比對站序 & 處理站間量\n",
    "df = pd.read_csv(r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\02_初步分析\\01_分時計次\\上下車區分票種分時計次.csv\")\n",
    "df = df.reindex(columns = ['InfoDate', 'WDWK', \n",
    "                           'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', 'Direction', \n",
    "                           'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence',\n",
    "                           'DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence', \n",
    "                           'Count'])\n",
    "df['InfoDate'] = pd.to_datetime(df['InfoDate'], errors='coerce')\n",
    "df['DataMonth'] = df['InfoDate'].dt.to_period('M')\n",
    "\n",
    "df = df[df['WDWK'].isin([0,1])]\n",
    "\n",
    "groupbycolumns = ['DataMonth', 'WDWK', \n",
    "                  'RouteUID', 'RouteName', 'SubRouteUID', 'SubRouteName', 'Direction', \n",
    "                  'BoardingStopUID', 'BoardingStopName', 'BoardingStopSequence',\n",
    "                  'DeboardingStopUID', 'DeboardingStopName', 'DeboardingStopSequence']\n",
    "\n",
    "df[groupbycolumns] = df[groupbycolumns].fillna('-99')\n",
    "df = df.groupby(groupbycolumns).agg({'Count': 'sum'}).reset_index()\n",
    "\n",
    "seqfolder = r\"D:\\B-Project\\2025\\6800\\Technical\\12票證資料\\TicketAnalysis\\00_TDX資料下載\\01公車站序資料\"\n",
    "df_seq = read_combined_dataframe(file_list=findfiles(seqfolder))\n",
    "df_seq = df_seq.reindex(columns = ['RouteUID', 'RouteName_Zh', 'SubRouteUID', 'SubRouteName_Zh', 'Direction', 'StopUID', 'StopName_Zh', 'StopSequence', 'PositionLon', 'PositionLat'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.merge(df, \n",
    "#                  df_seq.reindex(columns  =  ['RouteUID', 'SubRouteUID', 'Direction', 'StopSequence', 'StopUID', 'StopName_Zh']).drop_duplicates().rename(columns = {'StopSequence':'BoardingStopSequence'}),\n",
    "#                  on = ['RouteUID', 'SubRouteUID', 'Direction', 'BoardingStopSequence'], \n",
    "#                  how = 'left')\n",
    "# check[check['StopUID'] != check['BoardingStopUID']]\n",
    "# check2 = pd.merge(df, \n",
    "#                   df_seq.reindex(columns  =  ['RouteUID', 'SubRouteUID', 'Direction', 'StopSequence', 'StopUID', 'StopName_Zh']).drop_duplicates().rename(columns = {'StopSequence':'DeboardingStopSequence'}),\n",
    "#                   on = ['RouteUID', 'SubRouteUID', 'Direction', 'DeboardingStopSequence'], \n",
    "#                   how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b251814",
   "metadata": {},
   "outputs": [],
   "source": [
    "check[(check['StopUID'] != check['BoardingStopUID']) & (check['StopUID'] != '-99')].reindex(columns= ['RouteUID', 'SubRouteUID', 'Direction', 'BoardingStopSequence', 'BoardingStopUID', 'BoardingStopName', 'StopUID', 'StopName_Zh', 'Count' ]).groupby(['RouteUID', 'SubRouteUID', 'Direction', 'BoardingStopSequence', 'BoardingStopUID', 'BoardingStopName', 'StopUID', 'StopName_Zh']).agg({'Count':'sum'}).reset_index()['Count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq.reindex(columns  =  ['RouteUID', 'SubRouteUID', 'Direction', 'StopSequence', 'StopUID', 'StopName_Zh']).rename(columns = {'StopUID':'BoardingStopUID','StopSequence':'BoardingStopSequence_S', 'StopName_Zh':'StopName_S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd988489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15290f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq_unique = df_seq.sort_values(['SubRouteUID','Direction', 'StopSequence']).drop_duplicates(subset=['RouteUID','SubRouteUID','Direction','StopUID'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ['RouteUID','SubRouteUID','Direction','StopUID']\n",
    "\n",
    "df_seq_removed = df_seq.merge(\n",
    "    df_seq_unique[key],\n",
    "    on=key,\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")#.query(\"_merge == 'left_only'\") \\\n",
    " #.drop(columns=['_merge'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdf = pd.merge(df, \n",
    "                   df_seq.reindex(columns  =  ['RouteUID', 'SubRouteUID', 'Direction', 'StopSequence', 'StopUID', 'StopName_Zh']).rename(columns = {'StopUID':'BoardingStopUID','StopSequence':'BoardingStopSequence_S', 'StopName_Zh':'BoardingStopName_S'}).drop_duplicates(subset = ['RouteUID', 'SubRouteUID', 'Direction', 'BoardingStopUID']), \n",
    "                   on = ['RouteUID', 'SubRouteUID', 'Direction', 'BoardingStopUID'], \n",
    "                   how = 'left')\n",
    "\n",
    "checkdf = pd.merge(checkdf, \n",
    "                   df_seq.reindex(columns  =  ['RouteUID', 'SubRouteUID', 'Direction', 'StopSequence', 'StopUID', 'StopName_Zh']).rename(columns = {'StopUID':'DeboardingStopUID','StopSequence':'DeboardingStopSequence_S', 'StopName_Zh':'DeboardingStopName_S'}).drop_duplicates(subset = ['RouteUID', 'SubRouteUID', 'Direction', 'DeboardingStopUID']), \n",
    "                   on = ['RouteUID', 'SubRouteUID', 'Direction', 'DeboardingStopUID'], \n",
    "                   how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf807ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"起點站序不同:\", end = ' ')\n",
    "print(checkdf[checkdf['BoardingStopSequence'] != checkdf['BoardingStopSequence_S']]['Count'].sum(), \n",
    "      end = \"筆\\n\")\n",
    "\n",
    "print(\"迄點站序不同:\", end = \" \")\n",
    "print(checkdf[checkdf['DeboardingStopSequence'] != checkdf['DeboardingStopSequence_S']]['Count'].sum(), \n",
    "      end = \"筆\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776fa014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq[(df_seq['RouteUID'] == 'TAO188') & \n",
    "       (df_seq['Direction']) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3883ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdf[(checkdf['BoardingStopSequence_S'] > checkdf['DeboardingStopSequence_S']) &\n",
    "        (checkdf['RouteUID'] == 'NWT10453')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1236214",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdf[checkdf['BoardingStopSequence_S'] > checkdf['DeboardingStopSequence_S']][['RouteUID','RouteName', 'SubRouteUID', 'SubRouteName', 'Direction']].drop_duplicates().sort_values(['RouteUID', 'SubRouteUID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check2 = pd.merge(df, \n",
    "#                   df_seq.reindex(columns  =  ['RouteUID', 'SubRouteUID', 'Direction', 'StopSequence']).drop_duplicates().rename(columns = {'StopSequence':'DeboardingStopSequence'}),\n",
    "#                   on = ['RouteUID', 'SubRouteUID', 'Direction'], \n",
    "#                   how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65374210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(check))\n",
    "print(\"----\")\n",
    "print(len(check2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c11a84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ab2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check[(check['Hi']!=1) & (check['BoardingStopUID']!='-99')]['BoardingStopUID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c56aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check2[(check2['Hi']!=1) & (check2['DeboardingStopUID']!='-99')]['DeboardingStopUID'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
